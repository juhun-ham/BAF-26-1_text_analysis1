{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 텍스트 임베딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12-01 원핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나', '는', '자연어', '처리', '를', '배운다']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt  \n",
    "okt = Okt()  \n",
    "token = okt.morphs(\"나는 자연어 처리를 배운다\")  \n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나': 0, '는': 1, '자연어': 2, '처리': 3, '를': 4, '배운다': 5}\n"
     ]
    }
   ],
   "source": [
    "word2index = {}\n",
    "for voca in token:\n",
    "    if voca not in word2index.keys():\n",
    "        word2index[voca] = len(word2index)\n",
    "print(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(word, word2index):\n",
    "       one_hot_vector = [0]*(len(word2index))\n",
    "       index = word2index[word]\n",
    "       one_hot_vector[index] = 1\n",
    "       return one_hot_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoding(\"자연어\",word2index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12-04 영어 Word2Vec 학습 및 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 훈련 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # 정규표현식 클래스\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from lxml import etree\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ted_en-20160408.xml', <http.client.HTTPMessage at 0x324a81a10>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 다운로드\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/09.%20Word%20Embedding/dataset/ted_en-20160408.xml\", filename=\"ted_en-20160408.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 훈련 데이터 전처리 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xml 문법으로 작성되어 있음 -> 전처리 필요\n",
    "targetXML = open('ted_en-20160408.xml', 'r', encoding='UTF8')\n",
    "target_text = etree.parse(targetXML) # 트리 구조만 파싱\n",
    "\n",
    "# xml 파일로부터 <content>와  </content>사이의 내용만 가져온다.\n",
    "parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n",
    "\n",
    "# 정규 표현식의 sub 모듈을 통해 content 중간에 등장하는 (Audio), (Laughter) 등의 배경음 부분을 제거.\n",
    "# 해당 코드는 괄호로 구성된 내용을 제거.\n",
    "content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n",
    "\n",
    "# 입력 코퍼스에 대해서 NLTK를 이용하여 문장 토큰화를 수행.\n",
    "sent_text = sent_tokenize(content_text)\n",
    "\n",
    "# 각 문장에 대해서 구두점을 제거하고, 대문자를 소문자로 변환\n",
    "normalized_text = []\n",
    "for string in sent_text:\n",
    "    tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n",
    "    normalized_text.append(tokens)\n",
    "\n",
    "    \n",
    "# 각 문장에 대해서 nltk를 이용하여 단어 토큰화를 수행\n",
    "result = [word_tokenize(sentence) for sentence in normalized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 개수 : 273424\n"
     ]
    }
   ],
   "source": [
    "print('총 샘플의 개수 : {}'.format(len(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new']\n",
      "['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation']\n",
      "['both', 'are', 'necessary', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing']\n"
     ]
    }
   ],
   "source": [
    "# 샘플 3개만 출력\n",
    "for line in result[:3]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Word2Vec 훈련시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.4.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from gensim) (2.4.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from gensim) (1.11.4)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from gensim) (7.3.1)\n",
      "Collecting numpy>=1.18.5 (from gensim)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (114 kB)\n",
      "Requirement already satisfied: wrapt in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from smart_open>=1.8.1->gensim) (1.17.2)\n",
      "Downloading gensim-4.4.0-cp311-cp311-macosx_11_0_arm64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, gensim\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.4.1\n",
      "    Uninstalling numpy-2.4.1:\n",
      "      Successfully uninstalled numpy-2.4.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed gensim-4.4.0 numpy-1.26.4\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(sentences=result, vector_size=100, window=5, min_count=5, workers=4, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.8508875370025635), ('guy', 0.8218192458152771), ('boy', 0.7868929505348206), ('lady', 0.7816059589385986), ('gentleman', 0.7510153651237488), ('girl', 0.7481671571731567), ('kid', 0.7313878536224365), ('soldier', 0.7234143614768982), ('poet', 0.6905738115310669), ('david', 0.6853529810905457)]\n"
     ]
    }
   ],
   "source": [
    "model_result = model.wv.most_similar(\"man\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Word2Vec 모델 저장하고 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('eng_w2v') # 모델 저장\n",
    "loaded_model = KeyedVectors.load_word2vec_format('eng_w2v') # 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.8508875370025635), ('guy', 0.8218192458152771), ('boy', 0.7868929505348206), ('lady', 0.7816059589385986), ('gentleman', 0.7510153651237488), ('girl', 0.7481671571731567), ('kid', 0.7313878536224365), ('soldier', 0.7234143614768982), ('poet', 0.6905738115310669), ('david', 0.6853529810905457)]\n"
     ]
    }
   ],
   "source": [
    "model_result = loaded_model.most_similar('man')\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 한국어 Word2Vec 만들기(네이버 영화 리뷰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ratings.txt', <http.client.HTTPMessage at 0x1339ebd90>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"ratings.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_table('ratings.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
       "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
       "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
       "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data)) # 리뷰 개수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# null 값 존재 유무\n",
    "print(train_data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NULL 값 존재 유무 : False\n"
     ]
    }
   ],
   "source": [
    "# null 값 제거\n",
    "train_data = train_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n",
    "print('NULL 값 존재 유무 :', train_data.isnull().values.any()) # Null 값이 존재하는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199992\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data)) # 리뷰 개수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규 표현식을 통한 한글 외 문자 제거\n",
    "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을 배우는 학생으로 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산업...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리 시리즈는 부터 뉴까지 버릴께 하나도 없음 최고</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와 연기가 진짜 개쩔구나 지루할거라고 생각했는데 몰입해서 봤다 그래 이런게 진짜 영화지</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을 배우는 학생으로 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산업...      1\n",
       "2   4655635                   폴리스스토리 시리즈는 부터 뉴까지 버릴께 하나도 없음 최고      1\n",
       "3   9251303   와 연기가 진짜 개쩔구나 지루할거라고 생각했는데 몰입해서 봤다 그래 이런게 진짜 영화지      1\n",
       "4  10067386                         안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화      1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 정의\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 199992/199992 [07:15<00:00, 459.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# 형태소 분석기 okt를 사용한 토큰화 작업\n",
    "okt = Okt()\n",
    "\n",
    "tokenized_data = []\n",
    "for sentence in tqdm(train_data['document']):\n",
    "    tokenized_sentence = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n",
    "    tokenized_data.append(stopwords_removed_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['어리다', '때', '보고', '지금', '다시', '보다', '재밌다', 'ㅋㅋ'], ['디자인', '을', '배우다', '학생', '외국', '디자이너', '그', '일군', '전통', '을', '통해', '발전', '문화', '산업', '부럽다', '사실', '우리나라', '에서도', '그', '어렵다', '시절', '끝', '까지', '열정', '을', '지키다', '노라노', '같다', '전통', '있다', '저', '같다', '사람', '꿈', '을', '꾸다', '이루다', '나가다', '수', '있다', '것', '감사하다'], ['폴리스스토리', '시리즈', '부터', '뉴', '까지', '버리다', '하나', '없다', '최고']]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_data[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰의 최대 길이 : 72\n",
      "리뷰의 평균 길이 : 10.716703668146726\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 리뷰 길이 분포 확인\n",
    "print('리뷰의 최대 길이 :',max(len(l) for l in tokenized_data))\n",
    "print('리뷰의 평균 길이 :',sum(map(len, tokenized_data))/len(tokenized_data))\n",
    "plt.hist([len(s) for s in tokenized_data], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(sentences = tokenized_data, vector_size = 100, window = 5, min_count = 5, workers = 4, sg = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16477, 100)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 완성된 임베딩 벡터의 크기 확인\n",
    "model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('임원희', 0.844593346118927), ('최민수', 0.8323239088058472), ('안성기', 0.8307114839553833), ('서영희', 0.8231338858604431), ('박중훈', 0.8190014958381653), ('한석규', 0.8134115934371948), ('이민호', 0.8132481575012207), ('엄태웅', 0.8124527335166931), ('송강호', 0.8097203969955444), ('문소리', 0.8072735071182251)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(\"최민식\")) # 이 단어의 의미 자체가 아니라, 텍스트 내 문맥 패턴을 기반으로 학습했기 때문에, 동일한 문맥군에 속한 한국 배우 이름들이 가깝게 배치된 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('무협', 0.8787272572517395), ('슬래셔', 0.8661424517631531), ('호러', 0.859334409236908), ('느와르', 0.8426925539970398), ('블록버스터', 0.8319225311279297), ('물', 0.8203366994857788), ('무비', 0.8185327649116516), ('로코', 0.8142973184585571), ('물의', 0.805706799030304), ('홍콩', 0.7983956336975098)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(\"히어로\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 워드 임베딩 모델로부터 2개의 tsv 파일 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-21 17:32:07,706 - word2vec2tensor - INFO - running /opt/anaconda3/envs/myenv/lib/python3.11/site-packages/gensim/scripts/word2vec2tensor.py --input eng_w2v --output eng_w2v\n",
      "2026-01-21 17:32:07,706 - keyedvectors - INFO - loading projection weights from eng_w2v\n",
      "2026-01-21 17:32:08,729 - utils - INFO - KeyedVectors lifecycle event {'msg': 'loaded (21613, 100) matrix of type float32 from eng_w2v', 'binary': False, 'encoding': 'utf8', 'datetime': '2026-01-21T17:32:08.706024', 'gensim': '4.4.0', 'python': '3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]', 'platform': 'macOS-26.2-arm64-arm-64bit', 'event': 'load_word2vec_format'}\n",
      "2026-01-21 17:32:09,413 - word2vec2tensor - INFO - 2D tensor file saved to eng_w2v_tensor.tsv\n",
      "2026-01-21 17:32:09,413 - word2vec2tensor - INFO - Tensor metadata file saved to eng_w2v_metadata.tsv\n",
      "2026-01-21 17:32:09,413 - word2vec2tensor - INFO - finished running word2vec2tensor.py\n"
     ]
    }
   ],
   "source": [
    "!python -m gensim.scripts.word2vec2tensor --input eng_w2v --output eng_w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12-05 글로브와 패스트텍스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'electrofishing' not present in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/zoohunn/Desktop/비어플/[26-1]스터디/2주차/nlp기본_2주차_텍스트임베딩.ipynb 셀 46\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/zoohunn/Desktop/%E1%84%87%E1%85%B5%E1%84%8B%E1%85%A5%E1%84%91%E1%85%B3%E1%86%AF/%5B26-1%5D%E1%84%89%E1%85%B3%E1%84%90%E1%85%A5%E1%84%83%E1%85%B5/2%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1/nlp%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB_2%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1_%E1%84%90%E1%85%A6%E1%86%A8%E1%84%89%E1%85%B3%E1%84%90%E1%85%B3%E1%84%8B%E1%85%B5%E1%86%B7%E1%84%87%E1%85%A6%E1%84%83%E1%85%B5%E1%86%BC.ipynb#Y216sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mwv\u001b[39m.\u001b[39mmost_similar(\u001b[39m\"\u001b[39m\u001b[39melectrofishing\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/gensim/models/keyedvectors.py:843\u001b[0m, in \u001b[0;36mKeyedVectors.most_similar\u001b[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    840\u001b[0m         weight[idx] \u001b[39m=\u001b[39m item[\u001b[39m1\u001b[39m]\n\u001b[1;32m    842\u001b[0m \u001b[39m# compute the weighted average of all keys\u001b[39;00m\n\u001b[0;32m--> 843\u001b[0m mean \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_mean_vector(keys, weight, pre_normalize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, post_normalize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, ignore_missing\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    844\u001b[0m all_keys \u001b[39m=\u001b[39m [\n\u001b[1;32m    845\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_index(key) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m keys \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, _KEY_TYPES) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_index_for(key)\n\u001b[1;32m    846\u001b[0m ]\n\u001b[1;32m    848\u001b[0m \u001b[39mif\u001b[39;00m indexer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(topn, \u001b[39mint\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/gensim/models/keyedvectors.py:518\u001b[0m, in \u001b[0;36mKeyedVectors.get_mean_vector\u001b[0;34m(self, keys, weights, pre_normalize, post_normalize, ignore_missing)\u001b[0m\n\u001b[1;32m    516\u001b[0m         total_weight \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mabs\u001b[39m(weights[idx])\n\u001b[1;32m    517\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_missing:\n\u001b[0;32m--> 518\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mKey \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m not present in vocabulary\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    520\u001b[0m \u001b[39mif\u001b[39;00m total_weight \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    521\u001b[0m     mean \u001b[39m=\u001b[39m mean \u001b[39m/\u001b[39m total_weight\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'electrofishing' not present in vocabulary\""
     ]
    }
   ],
   "source": [
    "model.wv.most_similar(\"electrofishing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\bWord2Vec는 학습 데이터에 존재하지 않은 단어. 즉 모르는 단어에 대해서는 임베딩 벡터가 존재하지 않기 때문에 단어의 유사도 구할 수 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "model = FastText(result, vector_size=100, window=5, min_count=5, workers=4, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('electrolyte', 0.8601861000061035),\n",
       " ('electrolux', 0.8588662147521973),\n",
       " ('electro', 0.8468809723854065),\n",
       " ('electroshock', 0.8424067497253418),\n",
       " ('electroencephalogram', 0.829591691493988),\n",
       " ('airbag', 0.8237091302871704),\n",
       " ('electrochemical', 0.8217712044715881),\n",
       " ('airbus', 0.8206053972244263),\n",
       " ('electric', 0.8175140619277954),\n",
       " ('electron', 0.8148260712623596)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"electrofishing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12-06 파이토치의 nn.Embedding()\n",
    "- 임베딩 층을 만들어 훈련 데이터로부터 처음부터 임베딩 벡터를 학습하는 방법 시도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 임베딩 층은 룩업 테이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch 패키지\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 2, 'you': 3, 'know': 4, 'to': 5, 'need': 6, 'how': 7, 'unk': 0, 'pad': 1}\n"
     ]
    }
   ],
   "source": [
    "train_data = 'you need to know how to code'\n",
    "\n",
    "# 중복을 제거한 단어들의 집합인 단어 집합 생성.\n",
    "word_set = set(train_data.split())\n",
    "\n",
    "# 단어 집합의 각 단어에 고유한 정수 맵핑.\n",
    "vocab = {word: i+2 for i, word in enumerate(word_set)}\n",
    "vocab['unk'] = 0 # 사전에 없는 단어\n",
    "vocab['pad'] = 1 # 문장 길이를 맞추기 위한 채움 값\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 집합의 크기만큼의 행을 가지는 테이블 생성. -> 처음에 랜덤 값으로 초기화 \n",
    "embedding_table = torch.FloatTensor([\n",
    "                               [ 0.0,  0.0,  0.0],\n",
    "                               [ 0.0,  0.0,  0.0],\n",
    "                               [ 0.2,  0.9,  0.3],\n",
    "                               [ 0.1,  0.5,  0.7],\n",
    "                               [ 0.2,  0.1,  0.8],\n",
    "                               [ 0.4,  0.1,  0.1],\n",
    "                               [ 0.1,  0.8,  0.9],\n",
    "                               [ 0.6,  0.1,  0.1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 5, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = 'you need to run'.split()\n",
    "idxes = []\n",
    "\n",
    "# 각 단어를 정수로 변환\n",
    "for word in sample:\n",
    "    try:\n",
    "        idxes.append(vocab[word])\n",
    "    # 단어 집합에 없는 단어일 경우 <unk>로 대체된다.\n",
    "    except KeyError:\n",
    "        idxes.append(vocab['unk'])\n",
    "idxes = torch.LongTensor(idxes)\n",
    "idxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1000, 0.5000, 0.7000],\n",
      "        [0.1000, 0.8000, 0.9000],\n",
      "        [0.4000, 0.1000, 0.1000],\n",
      "        [0.0000, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# 각 정수를 인덱스로 임베딩 테이블에서 값을 가져온다.\n",
    "lookup_result = embedding_table[idxes, :]\n",
    "print(lookup_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 임베딩 층 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code', 'how', 'know', 'need', 'to', 'you'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = 'you need to know how to code'\n",
    "\n",
    "# 중복을 제거한 단어들의 집합인 단어 집합 생성.\n",
    "word_set = set(train_data.split())\n",
    "word_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 집합의 각 단어에 고유한 정수 맵핑.\n",
    "vocab = {tkn: i+2 for i, tkn in enumerate(word_set)}\n",
    "vocab['<unk>'] = 0\n",
    "vocab['<pad>'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(8, 3, padding_idx=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nn.Embedding()을 사용하여 학습 가능한 임베딩 테이블 만듬 -> 이것이 곧 룩업 테이블 \"단어 사전\"\n",
    "embedding_layer = nn.Embedding(num_embeddings=len(vocab), embedding_dim=3, padding_idx=1)\n",
    "embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-1.4007,  0.3494,  0.6181],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [-0.7364,  0.1992, -1.7797],\n",
      "        [ 1.0449, -0.8488, -0.4816],\n",
      "        [-1.7716,  0.7927,  0.8207],\n",
      "        [-0.2003,  0.1049, -0.8958],\n",
      "        [-0.0630, -0.6169,  0.6706],\n",
      "        [-0.8201,  1.6232,  0.8004]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer.weight) # 단어 집합 크기의 행을 가지는 임베딩 테이블 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12-07 사전 훈련된 워드 임베딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 사전 훈련된 임베딩을 사용하지 않는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import gensim # 임베딩과 토픽 모델링에 특화된 nlp 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 문장의 긍,부정을 판단하는 감성 분류 모델 만들 것임\n",
    "sentences = ['nice great best amazing', 'stop lies', 'pitiful nerd', 'excellent work', 'supreme quality', 'bad', 'highly respectable']\n",
    "y_train = [1, 0, 0, 1, 1, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 토큰화 된 결과 : [['nice', 'great', 'best', 'amazing'], ['stop', 'lies'], ['pitiful', 'nerd'], ['excellent', 'work'], ['supreme', 'quality'], ['bad'], ['highly', 'respectable']]\n"
     ]
    }
   ],
   "source": [
    "# 각 샘플에 대해서 단어 토큰화 수행\n",
    "tokenized_sentences = [sent.split() for sent in sentences]\n",
    "print('단어 토큰화 된 결과 :', tokenized_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 단어 수: 15\n"
     ]
    }
   ],
   "source": [
    "word_list = []\n",
    "for sent in tokenized_sentences:\n",
    "    for word in sent:\n",
    "        word_list.append(word)\n",
    "\n",
    "word_counts = Counter(word_list)\n",
    "print('총 단어 수:', len(word_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nice', 'great', 'best', 'amazing', 'stop', 'lies', 'pitiful', 'nerd', 'excellent', 'work', 'supreme', 'quality', 'bad', 'highly', 'respectable']\n"
     ]
    }
   ],
   "source": [
    "# 등장 빈도순으로 정렬\n",
    "vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "패딩 토큰, UNK 토큰을 고려한 단어 집합의 크기:  17\n"
     ]
    }
   ],
   "source": [
    "word_to_index = {}\n",
    "word_to_index['<PAD>'] = 0\n",
    "word_to_index['<UNK>'] = 1\n",
    "\n",
    "for index, word in enumerate(vocab):\n",
    "    word_to_index[word] = index + 2\n",
    "\n",
    "vocab_size = len(word_to_index)\n",
    "print('패딩 토큰, UNK 토큰을 고려한 단어 집합의 크기: ', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<UNK>': 1, 'nice': 2, 'great': 3, 'best': 4, 'amazing': 5, 'stop': 6, 'lies': 7, 'pitiful': 8, 'nerd': 9, 'excellent': 10, 'work': 11, 'supreme': 12, 'quality': 13, 'bad': 14, 'highly': 15, 'respectable': 16}\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3, 4, 5], [6, 7], [8, 9], [10, 11], [12, 13], [14], [15, 16]]\n"
     ]
    }
   ],
   "source": [
    "# 단어 집합을 이용하여 정수 인코딩 진행\n",
    "def texts_to_sequences(tokenized_X_data, word_to_index):\n",
    "  encoded_X_data = []\n",
    "  for sent in tokenized_X_data:\n",
    "    index_sequences = []\n",
    "    for word in sent:\n",
    "      try:\n",
    "          index_sequences.append(word_to_index[word])\n",
    "      except KeyError:\n",
    "          index_sequences.append(word_to_index[''])\n",
    "    encoded_X_data.append(index_sequences)\n",
    "  return encoded_X_data\n",
    "\n",
    "X_encoded = texts_to_sequences(tokenized_sentences, word_to_index)\n",
    "print(X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 길이: 4\n"
     ]
    }
   ],
   "source": [
    "# 현재 데이터의 최대 길이를 측정하고, 해당 길이로 패딩을 진행\n",
    "max_len = max(len(l) for l in X_encoded)\n",
    "print('최대 길이:', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "패딩 결과 :\n",
      "[[ 2  3  4  5]\n",
      " [ 6  7  0  0]\n",
      " [ 8  9  0  0]\n",
      " [10 11  0  0]\n",
      " [12 13  0  0]\n",
      " [14  0  0  0]\n",
      " [15 16  0  0]]\n"
     ]
    }
   ],
   "source": [
    "def pad_sequences(sentences, max_len):\n",
    "  features = np.zeros((len(sentences), max_len), dtype=int)\n",
    "  for index, sentence in enumerate(sentences):\n",
    "    if len(sentence) != 0:\n",
    "      features[index, :len(sentence)] = np.array(sentence)[:max_len]\n",
    "  return features\n",
    "\n",
    "X_train = pad_sequences(X_encoded, max_len=max_len)\n",
    "y_train = np.array(y_train)\n",
    "print('패딩 결과 :')\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Embedding()을 이용하여 모델 설계\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam # 최적화 알고리즘\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(embedding_dim * max_len, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # embedded.shape == (배치 크기, 문장의 길이, 임베딩 벡터의 차원)\n",
    "        embedded = self.embedding(x)\n",
    "\n",
    "        # flattend.shape == (배치 크기, 문장의 길이 × 임베딩 벡터의 차원)\n",
    "        flattened = self.flatten(embedded)\n",
    "\n",
    "        # output.shape == (배치 크기, 1)\n",
    "        output = self.fc(flattened)\n",
    "        return self.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 객체 선언\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "embedding_dim = 100\n",
    "simple_model = SimpleModel(vocab_size, embedding_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss() # 이진 분류 손실 함수\n",
    "optimizer = Adam(simple_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.long), torch.tensor(y_train, dtype=torch.float32))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.0947635173797607\n",
      "Epoch 2, Loss: 0.7884654998779297\n",
      "Epoch 3, Loss: 0.5528863668441772\n",
      "Epoch 4, Loss: 0.39972901344299316\n",
      "Epoch 5, Loss: 0.3090876340866089\n",
      "Epoch 6, Loss: 0.25849851965904236\n",
      "Epoch 7, Loss: 0.23159855604171753\n",
      "Epoch 8, Loss: 0.21776825189590454\n",
      "Epoch 9, Loss: 0.21001705527305603\n",
      "Epoch 10, Loss: 0.20366013050079346\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    for inputs, targets in train_dataloader:\n",
    "        # inputs.shape == (배치 크기, 문장 길이)\n",
    "        # targets.shape == (배치 크기)\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # outputs.shape == (배치 크기)\n",
    "        outputs = simple_model(inputs).view(-1)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 사전 훈련된 임베딩을 사용하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (5.2.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from gdown) (3.18.0)\n",
      "Requirement already satisfied: requests[socks] in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from gdown) (4.67.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from requests[socks]->gdown) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from requests[socks]->gdown) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from requests[socks]->gdown) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from requests[socks]->gdown) (2026.1.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1Av37IVBQAAntSe1X3MOAl5gvowQzd2_j\n",
      "From (redirected): https://drive.google.com/uc?id=1Av37IVBQAAntSe1X3MOAl5gvowQzd2_j&confirm=t&uuid=4139daea-56c6-4486-b885-d91b9b735a60\n",
      "To: /Users/zoohunn/Desktop/비어플/[26-1]스터디/2주차/GoogleNews-vectors-negative300.bin.gz\n",
      "100%|██████████████████████████████████████| 1.65G/1.65G [04:20<00:00, 6.33MB/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown\n",
    "!gdown --fuzzy https://drive.google.com/file/d/1Av37IVBQAAntSe1X3MOAl5gvowQzd2_j/view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구글의 사전 훈련된 word2vec 모델 로드\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 행렬의 크기 : (17, 300)\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "print('임베딩 행렬의 크기 :', embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec_model에 특정 단어의 임베딩 벡터가 없다면 None 리턴하는 함수 구현\n",
    "def get_vector(word):\n",
    "    if word in word2vec_model:\n",
    "        return word2vec_model[word]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 집합으로부터 단어를 1개씩 호출하여 word2vec_model에 해당 단어의 임베딩 벡터값이 존재하는 지 확인 -> 있으면 저장\n",
    "for word, i in word_to_index.items():\n",
    "    if i > 2:\n",
    "        temp = get_vector(word)\n",
    "        if temp is not None:\n",
    "            embedding_matrix[i] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# <PAD>나 <UNK>의 경우는 사전 훈련된 임베딩이 들어가지 않아서 0벡터임\n",
    "print(embedding_matrix[0])\n",
    "print(embedding_matrix[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index['great']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word2vec_model에서 'great'의 임베딩 벡터\n",
    "# embedding_matrix[3]이 일치하는지 체크\n",
    "np.all(word2vec_model['great'] == embedding_matrix[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainedEmbeddingModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(PretrainedEmbeddingModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "        self.embedding.weight.requires_grad = True\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(embedding_dim * max_len, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        flattened = self.flatten(embedded)\n",
    "        output = self.fc(flattened)\n",
    "        return self.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 객체 선언 -> 이미 정해진 300차원 임베딩 벡터 사용\n",
    "pretraiend_embedding_model = PretrainedEmbeddingModel(vocab_size, 300).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = Adam(pretraiend_embedding_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.long), torch.tensor(y_train, dtype=torch.float32))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6833153963088989\n",
      "Epoch 2, Loss: 0.6205196976661682\n",
      "Epoch 3, Loss: 0.5582743883132935\n",
      "Epoch 4, Loss: 0.4998626112937927\n",
      "Epoch 5, Loss: 0.446138858795166\n",
      "Epoch 6, Loss: 0.3972761332988739\n",
      "Epoch 7, Loss: 0.35318252444267273\n",
      "Epoch 8, Loss: 0.3136446177959442\n",
      "Epoch 9, Loss: 0.27838465571403503\n",
      "Epoch 10, Loss: 0.24708876013755798\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    for inputs, targets in train_dataloader:\n",
    "        # inputs.shape == (배치 크기, 문장 길이)\n",
    "        # targets.shape == (배치 크기)\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # outputs.shape == (배치 크기)\n",
    "        outputs = pretraiend_embedding_model(inputs).view(-1)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12-09 단어 단위 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Repeat is the best medicine for memory\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['best', 'medicine', 'for', 'is', 'memory', 'the', 'Repeat']\n"
     ]
    }
   ],
   "source": [
    "vocab = list(set(sentence))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {tkn: i for i, tkn in enumerate(vocab, 1)}  # 단어에 고유한 정수 부여\n",
    "word2index['<unk>']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best': 1, 'medicine': 2, 'for': 3, 'is': 4, 'memory': 5, 'the': 6, 'Repeat': 7, '<unk>': 0}\n"
     ]
    }
   ],
   "source": [
    "print(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(word2index['memory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'best', 2: 'medicine', 3: 'for', 4: 'is', 5: 'memory', 6: 'the', 7: 'Repeat', 0: '<unk>'}\n"
     ]
    }
   ],
   "source": [
    "# 수치화된 데이터를 단어로 바꾸기 위한 사전\n",
    "index2word = {v: k for k, v in word2index.items()}\n",
    "print(index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory\n"
     ]
    }
   ],
   "source": [
    "print(index2word[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data(sentence, word2index):\n",
    "    encoded = [word2index[token] for token in sentence] # 각 문자를 정수로 변환.\n",
    "    input_seq, label_seq = encoded[:-1], encoded[1:] # 입력 시퀀스와 레이블 시퀀스를 분리\n",
    "    input_seq = torch.LongTensor(input_seq).unsqueeze(0) # 배치 차원 추가\n",
    "    label_seq = torch.LongTensor(label_seq).unsqueeze(0) # 배치 차원 추가\n",
    "    return input_seq, label_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = build_data(sentence, word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7, 4, 6, 1, 2, 3]])\n",
      "tensor([[4, 6, 1, 2, 3, 5]])\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, vocab_size, input_size, hidden_size, batch_first=True):\n",
    "        super(Net, self).__init__()\n",
    "        self.embedding_layer = nn.Embedding(num_embeddings=vocab_size, # 워드 임베딩\n",
    "                                            embedding_dim=input_size)\n",
    "        self.rnn_layer = nn.RNN(input_size, hidden_size, # 입력 차원, 은닉 상태의 크기 정의\n",
    "                                batch_first=batch_first)\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size) # 출력은 원-핫 벡터의 크기를 가져야함. 또는 단어 집합의 크기만큼 가져야함.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1. 임베딩 층\n",
    "        # 크기변화: (배치 크기, 시퀀스 길이) => (배치 크기, 시퀀스 길이, 임베딩 차원)\n",
    "        output = self.embedding_layer(x)\n",
    "        # 2. RNN 층\n",
    "        # 크기변화: (배치 크기, 시퀀스 길이, 임베딩 차원)\n",
    "        # => output (배치 크기, 시퀀스 길이, 은닉층 크기), hidden (1, 배치 크기, 은닉층 크기)\n",
    "        output, hidden = self.rnn_layer(output)\n",
    "        # 3. 최종 출력층\n",
    "        # 크기변화: (배치 크기, 시퀀스 길이, 은닉층 크기) => (배치 크기, 시퀀스 길이, 단어장 크기)\n",
    "        output = self.linear(output)\n",
    "        # 4. view를 통해서 배치 차원 제거\n",
    "        # 크기변화: (배치 크기, 시퀀스 길이, 단어장 크기) => (배치 크기*시퀀스 길이, 단어장 크기)\n",
    "        return output.view(-1, output.size(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터\n",
    "vocab_size = len(word2index)  # 단어장의 크기는 임베딩 층, 최종 출력층에 사용된다.  토큰을 크기에 포함한다.\n",
    "input_size = 5  # 임베딩 된 차원의 크기 및 RNN 층 입력 차원의 크기\n",
    "hidden_size = 20  # RNN의 은닉층 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "model = Net(vocab_size, input_size, hidden_size, batch_first=True)\n",
    "# 손실함수 정의\n",
    "loss_function = nn.CrossEntropyLoss() # 소프트맥스 함수 포함이며 실제값은 원-핫 인코딩 안 해도 됨.\n",
    "# 옵티마이저 정의\n",
    "optimizer = optim.Adam(params=model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1845,  0.1770, -0.5387, -0.1359,  0.0845,  0.2758,  0.0963, -0.2057],\n",
      "        [-0.1718,  0.4261, -0.2884,  0.1364, -0.5177,  0.2397,  0.1974, -0.6339],\n",
      "        [-0.0806,  0.1805, -0.2005, -0.1820, -0.2357,  0.1985, -0.1069, -0.1423],\n",
      "        [-0.2039,  0.2344, -0.2770, -0.2576, -0.1656, -0.0395, -0.3506, -0.1213],\n",
      "        [-0.3067,  0.1113, -0.6249, -0.2901,  0.1560,  0.3480, -0.2596, -0.1560],\n",
      "        [-0.2820,  0.1710, -0.6634,  0.1790, -0.1230,  0.2014,  0.1018, -0.3850]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 임의로 예측해보기. 가중치는 전부 랜덤 초기화 된 상태이다.\n",
    "output = model(X)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 8])\n"
     ]
    }
   ],
   "source": [
    "print(output.shape) # (시퀀스 길이, 은닉층의 크기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치화된 데이터를 단어로 전환하는 함수\n",
    "decode = lambda y: [index2word[i] for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/201] 2.0011 \n",
      "Repeat memory best memory best memory memory\n",
      "\n",
      "[41/201] 1.3884 \n",
      "Repeat is the best medicine memory memory\n",
      "\n",
      "[81/201] 0.7760 \n",
      "Repeat is the best medicine for memory\n",
      "\n",
      "[121/201] 0.3979 \n",
      "Repeat is the best medicine for memory\n",
      "\n",
      "[161/201] 0.2165 \n",
      "Repeat is the best medicine for memory\n",
      "\n",
      "[201/201] 0.1343 \n",
      "Repeat is the best medicine for memory\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 훈련 시작\n",
    "for step in range(201):\n",
    "    # 경사 초기화\n",
    "    optimizer.zero_grad()\n",
    "    # 순방향 전파\n",
    "    output = model(X)\n",
    "    # 손실값 계산\n",
    "    loss = loss_function(output, Y.view(-1))\n",
    "    # 역방향 전파\n",
    "    loss.backward()\n",
    "    # 매개변수 업데이트\n",
    "    optimizer.step()\n",
    "    # 기록\n",
    "    if step % 40 == 0:\n",
    "        print(\"[{:02d}/201] {:.4f} \".format(step+1, loss))\n",
    "        pred = output.softmax(-1).argmax(-1).tolist()\n",
    "        print(\" \".join([\"Repeat\"] + decode(pred)))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
