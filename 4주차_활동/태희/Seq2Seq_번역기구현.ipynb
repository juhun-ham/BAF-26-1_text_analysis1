{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "077a0780-1736-484a-8f7b-2af40872de99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import urllib3\n",
    "import zipfile\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71a0baee-12c6-446e-8ff2-4764d2626456",
   "metadata": {},
   "outputs": [],
   "source": [
    "#약 19만개의 데이터 중 33,000개의 샘플만을 사용할 것\n",
    "num_samples = 33000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4c711ac-2361-45fd-b40f-ec2cc1852a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n"
     ]
    }
   ],
   "source": [
    "!wget -c http://www.manythings.org/anki/fra-eng.zip && unzip -o fra-eng.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e04300-2a6e-4f56-a3b1-4c56c5d2c658",
   "metadata": {},
   "source": [
    "설치가 안되어 수동설치함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4ff6b2-7f8a-4deb-ac67-308b484c33b1",
   "metadata": {},
   "source": [
    "구두점 등을 제거하거나 단어와 구분해주기 위한 전처리 함수를 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a7c7aff-a654-479d-b92c-f13c9e5f6a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "  # 프랑스어 악센트(accent) 삭제\n",
    "  # 예시 : 'déjà diné' -> deja dine\n",
    "  return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b98d85c5-abd5-4d04-ac14-8c8c725155ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sent):\n",
    "  # 악센트 삭제 함수 호출\n",
    "  sent = unicode_to_ascii(sent.lower())\n",
    "\n",
    "  # 단어와 구두점 사이에 공백을 만듭니다.\n",
    "  # Ex) \"he is a boy.\" => \"he is a boy .\"\n",
    "  sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
    "\n",
    "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환합니다.\n",
    "  sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
    "\n",
    "  # 다수 개의 공백을 하나의 공백으로 치환\n",
    "  sent = re.sub(r\"\\s+\", \" \", sent)\n",
    "  return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0153e7d1-10ca-4d71-a46c-d30795e5264c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocessed_data():\n",
    "  encoder_input, decoder_input, decoder_target = [], [], []\n",
    "\n",
    "  with open(\"fra-eng/fra.txt\", \"r\", encoding=\"utf-8\") as lines:\n",
    "    for i, line in enumerate(lines):\n",
    "      # source 데이터와 target 데이터 분리\n",
    "      src_line, tar_line, _ = line.strip().split('\\t')\n",
    "\n",
    "      # source 데이터 전처리\n",
    "      src_line = [w for w in preprocess_sentence(src_line).split()]\n",
    "\n",
    "      # target 데이터 전처리\n",
    "      tar_line = preprocess_sentence(tar_line)\n",
    "      tar_line_in = [w for w in (\"<sos> \" + tar_line).split()]\n",
    "      tar_line_out = [w for w in (tar_line + \" <eos>\").split()]\n",
    "\n",
    "      encoder_input.append(src_line)\n",
    "      decoder_input.append(tar_line_in)\n",
    "      decoder_target.append(tar_line_out)\n",
    "\n",
    "      if i == num_samples - 1:\n",
    "        break\n",
    "\n",
    "  return encoder_input, decoder_input, decoder_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8fc2bc2-103f-45f4-b2bf-0c0b0d94656a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 전 영어 문장 : Have you had dinner?\n",
      "전처리 후 영어 문장 : have you had dinner ?\n",
      "전처리 전 프랑스어 문장 : Avez-vous déjà diné?\n",
      "전처리 후 프랑스어 문장 : avez vous deja dine ?\n"
     ]
    }
   ],
   "source": [
    "# 전처리 테스트\n",
    "en_sent = u\"Have you had dinner?\"\n",
    "fr_sent = u\"Avez-vous déjà diné?\"\n",
    "\n",
    "print('전처리 전 영어 문장 :', en_sent)\n",
    "print('전처리 후 영어 문장 :',preprocess_sentence(en_sent))\n",
    "print('전처리 전 프랑스어 문장 :', fr_sent)\n",
    "print('전처리 후 프랑스어 문장 :', preprocess_sentence(fr_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc38d097-87d9-4acf-a4de-28fbd5ebe7fb",
   "metadata": {},
   "source": [
    "- 전체 데이터에서 33,000개의 샘플에 대해서 전처리를 수행한다.\n",
    "- 또한 훈련 과정에서 교사 강요(Teacher Forcing)을 사용할 예정이므로, 훈련 시 사용할 디코더의 입력 시퀀스와 실제값을 따로 분리하여 저장한다.\n",
    "- 입력 시퀀스에는 시작을 의미하는 토큰인 <sos>를 추가하고, 출력 시퀀스에는 종료를 의미하는 토큰인 <eos>를 추가한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40b40322-0490-4f90-a9b8-2ce440219f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코더의 입력 : [['go', '.'], ['go', '.'], ['go', '.'], ['go', '.'], ['hi', '.']]\n",
      "디코더의 입력 : [['<sos>', 'va', '!'], ['<sos>', 'marche', '.'], ['<sos>', 'en', 'route', '!'], ['<sos>', 'bouge', '!'], ['<sos>', 'salut', '!']]\n",
      "디코더의 레이블 : [['va', '!', '<eos>'], ['marche', '.', '<eos>'], ['en', 'route', '!', '<eos>'], ['bouge', '!', '<eos>'], ['salut', '!', '<eos>']]\n"
     ]
    }
   ],
   "source": [
    "sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()\n",
    "print('인코더의 입력 :',sents_en_in[:5])\n",
    "print('디코더의 입력 :',sents_fra_in[:5])\n",
    "print('디코더의 레이블 :',sents_fra_out[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9022a112-93da-4308-b5dc-6d5dab57ae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 집합을 형성\n",
    "# build_vocab은 입력된 데이터로부터 단어의 등장 빈도순으로 정렬 후에 등장 빈도가 높은 순서일 수록 낮은 정수를 부여함\n",
    "#패딩 토큰을 위한 <PAD> 토큰은 0번, OOV에 대응하기 위한 <UNK> 토큰은 1번에 할당함\n",
    "\n",
    "def build_vocab(sents):\n",
    "  word_list = []\n",
    "\n",
    "  for sent in sents:\n",
    "      for word in sent:\n",
    "        word_list.append(word)\n",
    "\n",
    "  # 각 단어별 등장 빈도를 계산하여 등장 빈도가 높은 순서로 정렬\n",
    "  word_counts = Counter(word_list)\n",
    "  vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "  word_to_index = {}\n",
    "  word_to_index['<PAD>'] = 0\n",
    "  word_to_index['<UNK>'] = 1\n",
    "\n",
    "  # 등장 빈도가 높은 단어일수록 낮은 정수를 부여\n",
    "  for index, word in enumerate(vocab) :\n",
    "    word_to_index[word] = index + 2\n",
    "\n",
    "  return word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3704886-a9bc-4f4b-acd6-8d65fd464fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어 집합의 크기 : 4508, 프랑스어 단어 집합의 크기 : 7889\n"
     ]
    }
   ],
   "source": [
    "#영어를 위한 단어 집합 src_vocab과 프랑스어를 이용한 단어 집합 tar_vocab를 형성\n",
    "\n",
    "src_vocab = build_vocab(sents_en_in)\n",
    "tar_vocab = build_vocab(sents_fra_in + sents_fra_out)\n",
    "\n",
    "src_vocab_size = len(src_vocab)\n",
    "tar_vocab_size = len(tar_vocab)\n",
    "print(\"영어 단어 집합의 크기 : {:d}, 프랑스어 단어 집합의 크기 : {:d}\".format(src_vocab_size, tar_vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96d27b42-5732-447a-9b05-f4f5454fcc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수로부터 단어를 얻는 딕셔너리를 각각 형성-> 훈련을 마치고 예측값과 실제값을 비교하는 단계에서 사용됨\n",
    "\n",
    "index_to_src = {v: k for k, v in src_vocab.items()}\n",
    "index_to_tar = {v: k for k, v in tar_vocab.items()}\n",
    "\n",
    "def texts_to_sequences(sents, word_to_index):\n",
    "  encoded_X_data = []\n",
    "  for sent in tqdm(sents):\n",
    "    index_sequences = []\n",
    "    for word in sent:\n",
    "      try:\n",
    "          index_sequences.append(word_to_index[word])\n",
    "      except KeyError:\n",
    "          index_sequences.append(word_to_index['<UNK>'])\n",
    "    encoded_X_data.append(index_sequences)\n",
    "  return encoded_X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e1f4ade-027b-4aa0-aa94-286721c636eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 33000/33000 [00:00<00:00, 440355.28it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 33000/33000 [00:00<00:00, 96758.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 33000/33000 [00:00<00:00, 372409.72it/s]\n"
     ]
    }
   ],
   "source": [
    "encoder_input = texts_to_sequences(sents_en_in, src_vocab)\n",
    "decoder_input = texts_to_sequences(sents_fra_in, tar_vocab)\n",
    "decoder_target = texts_to_sequences(sents_fra_out, tar_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4efb4ae-5dce-4eaf-a395-e1bb4b0b0a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0, 정수 인코딩 전: ['go', '.'], 정수 인코딩 후: [27, 2]\n",
      "Index: 1, 정수 인코딩 전: ['go', '.'], 정수 인코딩 후: [27, 2]\n",
      "Index: 2, 정수 인코딩 전: ['go', '.'], 정수 인코딩 후: [27, 2]\n",
      "Index: 3, 정수 인코딩 전: ['go', '.'], 정수 인코딩 후: [27, 2]\n",
      "Index: 4, 정수 인코딩 전: ['hi', '.'], 정수 인코딩 후: [736, 2]\n"
     ]
    }
   ],
   "source": [
    "# 상위 5개의 샘플에 대해서 정수 인코딩 전, 후 문장 출력\n",
    "# 인코더 입력이므로 <sos>나 <eos>가 없음\n",
    "for i, (item1, item2) in zip(range(5), zip(sents_en_in, encoder_input)):\n",
    "    print(f\"Index: {i}, 정수 인코딩 전: {item1}, 정수 인코딩 후: {item2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51c6c536-d0e8-4433-9934-bac3acb42916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sentences, max_len=None):\n",
    "    # 최대 길이 값이 주어지지 않을 경우 데이터 내 최대 길이로 패딩\n",
    "    if max_len is None:\n",
    "        max_len = max([len(sentence) for sentence in sentences])\n",
    "\n",
    "    features = np.zeros((len(sentences), max_len), dtype=int)\n",
    "    for index, sentence in enumerate(sentences):\n",
    "        if len(sentence) != 0:\n",
    "            features[index, :len(sentence)] = np.array(sentence)[:max_len]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6bd54333-9898-4b48-bf60-7bbaa7d357b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = pad_sequences(encoder_input)\n",
    "decoder_input = pad_sequences(decoder_input)\n",
    "decoder_target = pad_sequences(decoder_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28f9e5b7-a7fb-4dd0-9fac-509590c540d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코더의 입력의 크기(shape) : (33000, 7)\n",
      "디코더의 입력의 크기(shape) : (33000, 16)\n",
      "디코더의 레이블의 크기(shape) : (33000, 16)\n"
     ]
    }
   ],
   "source": [
    "# 데이터의 크기를 확인\n",
    "\n",
    "print('인코더의 입력의 크기(shape) :',encoder_input.shape)\n",
    "print('디코더의 입력의 크기(shape) :',decoder_input.shape)\n",
    "print('디코더의 레이블의 크기(shape) :',decoder_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8882230b-78dd-4cac-9706-2feb9c0e72df",
   "metadata": {},
   "source": [
    "테스트 데이터를 분리하기 전 데이터를 섞어준다. 이를 위해서 순서가 섞인 정수 시퀀스 리스트를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb405988-ca98-4e2c-a1d9-900b941dd0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤 시퀀스 : [32152  8074 32299 ... 15630 18910 18098]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print('랜덤 시퀀스 :',indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2f73475-869f-4787-beef-9bb249fdbb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "161c13b4-c3bf-4d81-89fe-c8ffa7438c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['you', 're', 'big', '.', '<PAD>', '<PAD>', '<PAD>']\n",
      "['<sos>', 'vous', 'etes', 'grands', '.', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "['vous', 'etes', 'grands', '.', '<eos>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "# 임의로  30,997번째 샘플을 출력\n",
    "# 이때 decoder_input과 decoder_target은 데이터의 구조상으로 앞에 붙은 <sos> 토큰과 뒤에 붙은 <eos>을 제외하면 동일한 시퀀스를 가져야 한다\n",
    "\n",
    "print([index_to_src[word] for word in encoder_input[30997]])\n",
    "print([index_to_tar[word] for word in decoder_input[30997]])\n",
    "print([index_to_tar[word] for word in decoder_target[30997]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ef8eac9-e4e0-4fb0-a78f-a0d53b6ddeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터의 개수 : 3300\n"
     ]
    }
   ],
   "source": [
    "#33,000개의 10%에 해당되는 3,300개의 데이터를 테스트 데이터로 사용한다\n",
    "\n",
    "n_of_val = int(33000*0.1)\n",
    "print('검증 데이터의 개수 :',n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbbbc185-ecb0-4691-9138-c1a93254fcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b33480f-c1d0-453b-854f-76a396993a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 source 데이터의 크기 : (29700, 7)\n",
      "훈련 target 데이터의 크기 : (29700, 16)\n",
      "훈련 target 레이블의 크기 : (29700, 16)\n",
      "테스트 source 데이터의 크기 : (3300, 7)\n",
      "테스트 target 데이터의 크기 : (3300, 16)\n",
      "테스트 target 레이블의 크기 : (3300, 16)\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터와 테스트 데이터의 크기(shape)를 출력\n",
    "\n",
    "print('훈련 source 데이터의 크기 :',encoder_input_train.shape)\n",
    "print('훈련 target 데이터의 크기 :',decoder_input_train.shape)\n",
    "print('훈련 target 레이블의 크기 :',decoder_target_train.shape)\n",
    "print('테스트 source 데이터의 크기 :',encoder_input_test.shape)\n",
    "print('테스트 target 데이터의 크기 :',decoder_input_test.shape)\n",
    "print('테스트 target 레이블의 크기 :',decoder_target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d558936-bc50-4cfb-be2c-1ea28b7278fb",
   "metadata": {},
   "source": [
    "## 기계번역 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e20bcfd-c7a3-4955-b08b-8c992674ed3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "embedding_dim = 256\n",
    "hidden_units = 256\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, src_vocab_size, embedding_dim, hidden_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(src_vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_units, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape == (batch_size, seq_len, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        # hidden.shape == (1, batch_size, hidden_units), cell.shape == (1, batch_size, hidden_units)\n",
    "        _, (hidden, cell) = self.lstm(x)\n",
    "        # 인코더의 출력은 hidden state, cell state\n",
    "        return hidden, cell\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, tar_vocab_size, embedding_dim, hidden_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(tar_vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_units, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_units, tar_vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "\n",
    "        # x.shape == (batch_size, seq_len, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # 디코더의 LSTM으로 인코더의 hidden state, cell state를 전달.\n",
    "        # output.shape == (batch_size, seq_len, hidden_units)\n",
    "        # hidden.shape == (1, batch_size, hidden_units)\n",
    "        # cell.shape == (1, batch_size, hidden_units)\n",
    "        output, (hidden, cell) = self.lstm(x, (hidden, cell))\n",
    "\n",
    "        # output.shape: (batch_size, seq_len, tar_vocab_size)\n",
    "        output = self.fc(output)\n",
    "\n",
    "        # 디코더의 출력은 예측값, hidden state, cell state\n",
    "        return output, hidden, cell\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        hidden, cell = self.encoder(src)\n",
    "\n",
    "        # 훈련 중에는 디코더의 출력 중 오직 output만 사용한다.\n",
    "        output, _, _ = self.decoder(trg, hidden, cell)\n",
    "        return output\n",
    "\n",
    "encoder = Encoder(src_vocab_size, embedding_dim, hidden_units)\n",
    "decoder = Decoder(tar_vocab_size, embedding_dim, hidden_units)\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca3b0504-d5e5-473d-aa38-778bd39963e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(4508, 256, padding_idx=0)\n",
      "    (lstm): LSTM(256, 256, batch_first=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(7889, 256, padding_idx=0)\n",
      "    (lstm): LSTM(256, 256, batch_first=True)\n",
      "    (fc): Linear(in_features=256, out_features=7889, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9588fcb9-62de-4274-a0c4-651f07998f00",
   "metadata": {},
   "source": [
    "Encoder 클래스\n",
    "- 입력 시퀀스를 받아 해당 시퀀스의 정보를 압축하여 context vector로 변환하는 역할을 함.\n",
    "- Encoder는 임베딩 레이어와 LSTM 레이어로 구성되어 있음.\n",
    "- 임베딩 레이어는 입력 시퀀스의 각 토큰을 고정 크기의 벡터로 변환하고, LSTM 레이어는 시퀀스의 순서 정보를 고려하여 해당 시퀀스를 요약함.\n",
    "- Encoder의 forward 메서드는 입력 시퀀스를 받아 LSTM의 hidden state와 cell state를 반환함.\r\n",
    "\r\n",
    "Decoder 클  \n",
    "- 는 Encoder에서 생성된 context vector(인코더의 마지막 은닉 상태)를 기반으로 출력 시퀀스를 생성하는 역할함.\n",
    "- . Decoder 또한 임베딩 레이어와 LSTM 레이어로 구성되어음.\n",
    "- . Decoder의 LSTM은 Encoder에서 전달받은 hidden state와 cell state를 초기 상태로 사용하여 출력 시퀀스를 함.\n",
    "- . Decoder의 forward 메서드는 입력 시퀀스, hidden state, cell state를 받아 출력 시퀀스, 업데이트된 hidden state와 cell state를 함. 이루어집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8206a7-8ac3-433d-a857-d83e308433b4",
   "metadata": {},
   "source": [
    "#### 평가함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "209ed87c-564f-4289-8478-2597900e3649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, dataloader, loss_function, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for encoder_inputs, decoder_inputs, decoder_targets in dataloader:\n",
    "            encoder_inputs = encoder_inputs.to(device)\n",
    "            decoder_inputs = decoder_inputs.to(device)\n",
    "            decoder_targets = decoder_targets.to(device)\n",
    "\n",
    "            # 순방향 전파\n",
    "            # outputs.shape == (batch_size, seq_len, tar_vocab_size)\n",
    "            outputs = model(encoder_inputs, decoder_inputs)\n",
    "\n",
    "            # 손실 계산\n",
    "            # outputs.view(-1, outputs.size(-1))의 shape는 (batch_size * seq_len, tar_vocab_size)\n",
    "            # decoder_targets.view(-1)의 shape는 (batch_size * seq_len)\n",
    "            loss = loss_function(outputs.view(-1, outputs.size(-1)), decoder_targets.view(-1))\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # 정확도 계산 (패딩 토큰 제외)\n",
    "            mask = decoder_targets != 0\n",
    "            total_correct += ((outputs.argmax(dim=-1) == decoder_targets) * mask).sum().item()\n",
    "            total_count += mask.sum().item()\n",
    "\n",
    "    return total_loss / len(dataloader), total_correct / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "276ef1e0-db66-44cb-8237-c8e4280d421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train_tensor = torch.tensor(encoder_input_train, dtype=torch.long)\n",
    "decoder_input_train_tensor = torch.tensor(decoder_input_train, dtype=torch.long)\n",
    "decoder_target_train_tensor = torch.tensor(decoder_target_train, dtype=torch.long)\n",
    "\n",
    "encoder_input_test_tensor = torch.tensor(encoder_input_test, dtype=torch.long)\n",
    "decoder_input_test_tensor = torch.tensor(decoder_input_test, dtype=torch.long)\n",
    "decoder_target_test_tensor = torch.tensor(decoder_target_test, dtype=torch.long)\n",
    "\n",
    "# 데이터셋 및 데이터로더 생성\n",
    "batch_size = 128\n",
    "\n",
    "train_dataset = TensorDataset(encoder_input_train_tensor, decoder_input_train_tensor, decoder_target_train_tensor)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_dataset = TensorDataset(encoder_input_test_tensor, decoder_input_test_tensor, decoder_target_test_tensor)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3a66fc1-dedd-4fed-b3c3-60df9d1366b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(4508, 256, padding_idx=0)\n",
       "    (lstm): LSTM(256, 256, batch_first=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(7889, 256, padding_idx=0)\n",
       "    (lstm): LSTM(256, 256, batch_first=True)\n",
       "    (fc): Linear(in_features=256, out_features=7889, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 설정\n",
    "num_epochs = 30\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24c422e-ce06-46bd-b374-529234debd02",
   "metadata": {},
   "source": [
    "#### 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "73e7246d-0a62-480c-8280-672fd83a1392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30 | Train Loss: 2.9390 | Train Acc: 0.5250 | Valid Loss: 3.0276 | Valid Acc: 0.5242\n",
      "Validation loss improved from inf to 3.0276. 체크포인트를 저장합니다.\n",
      "Epoch: 2/30 | Train Loss: 2.2787 | Train Acc: 0.5998 | Valid Loss: 2.4855 | Valid Acc: 0.5914\n",
      "Validation loss improved from 3.0276 to 2.4855. 체크포인트를 저장합니다.\n",
      "Epoch: 3/30 | Train Loss: 1.8639 | Train Acc: 0.6432 | Valid Loss: 2.1848 | Valid Acc: 0.6260\n",
      "Validation loss improved from 2.4855 to 2.1848. 체크포인트를 저장합니다.\n",
      "Epoch: 4/30 | Train Loss: 1.5543 | Train Acc: 0.6826 | Valid Loss: 1.9979 | Valid Acc: 0.6506\n",
      "Validation loss improved from 2.1848 to 1.9979. 체크포인트를 저장합니다.\n",
      "Epoch: 5/30 | Train Loss: 1.3006 | Train Acc: 0.7225 | Valid Loss: 1.8560 | Valid Acc: 0.6681\n",
      "Validation loss improved from 1.9979 to 1.8560. 체크포인트를 저장합니다.\n",
      "Epoch: 6/30 | Train Loss: 1.0820 | Train Acc: 0.7592 | Valid Loss: 1.7384 | Valid Acc: 0.6849\n",
      "Validation loss improved from 1.8560 to 1.7384. 체크포인트를 저장합니다.\n",
      "Epoch: 7/30 | Train Loss: 0.9044 | Train Acc: 0.7927 | Valid Loss: 1.6616 | Valid Acc: 0.6953\n",
      "Validation loss improved from 1.7384 to 1.6616. 체크포인트를 저장합니다.\n",
      "Epoch: 8/30 | Train Loss: 0.7495 | Train Acc: 0.8231 | Valid Loss: 1.5939 | Valid Acc: 0.7025\n",
      "Validation loss improved from 1.6616 to 1.5939. 체크포인트를 저장합니다.\n",
      "Epoch: 9/30 | Train Loss: 0.6328 | Train Acc: 0.8501 | Valid Loss: 1.5508 | Valid Acc: 0.7093\n",
      "Validation loss improved from 1.5939 to 1.5508. 체크포인트를 저장합니다.\n",
      "Epoch: 10/30 | Train Loss: 0.5249 | Train Acc: 0.8731 | Valid Loss: 1.5082 | Valid Acc: 0.7172\n",
      "Validation loss improved from 1.5508 to 1.5082. 체크포인트를 저장합니다.\n",
      "Epoch: 11/30 | Train Loss: 0.4476 | Train Acc: 0.8882 | Valid Loss: 1.4924 | Valid Acc: 0.7204\n",
      "Validation loss improved from 1.5082 to 1.4924. 체크포인트를 저장합니다.\n",
      "Epoch: 12/30 | Train Loss: 0.3821 | Train Acc: 0.8997 | Valid Loss: 1.4817 | Valid Acc: 0.7231\n",
      "Validation loss improved from 1.4924 to 1.4817. 체크포인트를 저장합니다.\n",
      "Epoch: 13/30 | Train Loss: 0.3328 | Train Acc: 0.9089 | Valid Loss: 1.4803 | Valid Acc: 0.7230\n",
      "Validation loss improved from 1.4817 to 1.4803. 체크포인트를 저장합니다.\n",
      "Epoch: 14/30 | Train Loss: 0.2970 | Train Acc: 0.9144 | Valid Loss: 1.4902 | Valid Acc: 0.7219\n",
      "Epoch: 15/30 | Train Loss: 0.2733 | Train Acc: 0.9188 | Valid Loss: 1.4931 | Valid Acc: 0.7256\n",
      "Epoch: 16/30 | Train Loss: 0.2496 | Train Acc: 0.9218 | Valid Loss: 1.4944 | Valid Acc: 0.7274\n",
      "Epoch: 17/30 | Train Loss: 0.2316 | Train Acc: 0.9244 | Valid Loss: 1.5055 | Valid Acc: 0.7260\n",
      "Epoch: 18/30 | Train Loss: 0.2156 | Train Acc: 0.9268 | Valid Loss: 1.5164 | Valid Acc: 0.7269\n",
      "Epoch: 19/30 | Train Loss: 0.2063 | Train Acc: 0.9274 | Valid Loss: 1.5293 | Valid Acc: 0.7244\n",
      "Epoch: 20/30 | Train Loss: 0.1962 | Train Acc: 0.9293 | Valid Loss: 1.5370 | Valid Acc: 0.7288\n",
      "Epoch: 21/30 | Train Loss: 0.1885 | Train Acc: 0.9297 | Valid Loss: 1.5522 | Valid Acc: 0.7239\n",
      "Epoch: 22/30 | Train Loss: 0.1820 | Train Acc: 0.9301 | Valid Loss: 1.5616 | Valid Acc: 0.7272\n",
      "Epoch: 23/30 | Train Loss: 0.1760 | Train Acc: 0.9310 | Valid Loss: 1.5705 | Valid Acc: 0.7248\n",
      "Epoch: 24/30 | Train Loss: 0.1734 | Train Acc: 0.9309 | Valid Loss: 1.5769 | Valid Acc: 0.7243\n",
      "Epoch: 25/30 | Train Loss: 0.1691 | Train Acc: 0.9314 | Valid Loss: 1.5864 | Valid Acc: 0.7251\n",
      "Epoch: 26/30 | Train Loss: 0.1653 | Train Acc: 0.9319 | Valid Loss: 1.6117 | Valid Acc: 0.7248\n",
      "Epoch: 27/30 | Train Loss: 0.1668 | Train Acc: 0.9313 | Valid Loss: 1.6176 | Valid Acc: 0.7247\n",
      "Epoch: 28/30 | Train Loss: 0.1626 | Train Acc: 0.9318 | Valid Loss: 1.6152 | Valid Acc: 0.7228\n",
      "Epoch: 29/30 | Train Loss: 0.1595 | Train Acc: 0.9320 | Valid Loss: 1.6262 | Valid Acc: 0.7247\n",
      "Epoch: 30/30 | Train Loss: 0.1553 | Train Acc: 0.9322 | Valid Loss: 1.6306 | Valid Acc: 0.7264\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # 훈련 모드\n",
    "    model.train()\n",
    "\n",
    "    for encoder_inputs, decoder_inputs, decoder_targets in train_dataloader:\n",
    "        encoder_inputs = encoder_inputs.to(device)\n",
    "        decoder_inputs = decoder_inputs.to(device)\n",
    "        decoder_targets = decoder_targets.to(device)\n",
    "\n",
    "        # 기울기 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 순방향 전파\n",
    "        # outputs.shape == (batch_size, seq_len, tar_vocab_size)\n",
    "        outputs = model(encoder_inputs, decoder_inputs)\n",
    "\n",
    "        # 손실 계산 및 역방향 전파\n",
    "        # outputs.view(-1, outputs.size(-1))의 shape는 (batch_size * seq_len, tar_vocab_size)\n",
    "        # decoder_targets.view(-1)의 shape는 (batch_size * seq_len)\n",
    "        loss = loss_function(outputs.view(-1, outputs.size(-1)), decoder_targets.view(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        # 가중치 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss, train_acc = evaluation(model, train_dataloader, loss_function, device)\n",
    "    valid_loss, valid_acc = evaluation(model, valid_dataloader, loss_function, device)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Valid Loss: {valid_loss:.4f} | Valid Acc: {valid_acc:.4f}')\n",
    "\n",
    "    # 검증 손실이 최소일 때 체크포인트 저장\n",
    "    if valid_loss < best_val_loss:\n",
    "        print(f'Validation loss improved from {best_val_loss:.4f} to {valid_loss:.4f}. 체크포인트를 저장합니다.')\n",
    "        best_val_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'best_model_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e3d7c9-5bb3-4548-974c-a28a58ab3157",
   "metadata": {},
   "source": [
    "검증 데이터 손실이 가장 최소일 때의 모델을 로드하고 다시 재평가한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "11ce2b8c-3c1c-46db-b910-b0418bc0a891",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\강태희\\AppData\\Local\\Temp\\ipykernel_12712\\2929441124.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model_checkpoint.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model validation loss: 1.4803\n",
      "Best model validation accuracy: 0.7230\n"
     ]
    }
   ],
   "source": [
    "# 모델 로드\n",
    "model.load_state_dict(torch.load('best_model_checkpoint.pth'))\n",
    "\n",
    "# 모델을 device에 올립니다.\n",
    "model.to(device)\n",
    "\n",
    "# 검증 데이터에 대한 정확도와 손실 계산\n",
    "val_loss, val_accuracy = evaluation(model, valid_dataloader, loss_function, device)\n",
    "\n",
    "print(f'Best model validation loss: {val_loss:.4f}')\n",
    "print(f'Best model validation accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3bd2c73-b433-4e2b-8ac7-31d95287ad20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(tar_vocab['<sos>'])\n",
    "print(tar_vocab['<eos>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d6c104-037c-438c-87a2-8eeb617cfc70",
   "metadata": {},
   "source": [
    "## seq2seq 기계 번역기 동작시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1e53ac-94dc-453d-97e2-578d17a35c6c",
   "metadata": {},
   "source": [
    "seq2seq는 훈련 과정(교사 강요)과 테스트 과정에서의 동작 방식이 다르기에 테스트 과정을 위해 모델을 다시 설계해주어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9572dfff-8f75-4da7-a6d1-65930f838229",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_src = {v: k for k, v in src_vocab.items()}\n",
    "index_to_tar = {v: k for k, v in tar_vocab.items()}\n",
    "\n",
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq_to_src(input_seq):\n",
    "  sentence = ''\n",
    "  for encoded_word in input_seq:\n",
    "    if(encoded_word != 0):\n",
    "      sentence = sentence + index_to_src[encoded_word] + ' '\n",
    "  return sentence\n",
    "\n",
    "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq_to_tar(input_seq):\n",
    "  sentence = ''\n",
    "  for encoded_word in input_seq:\n",
    "    if(encoded_word != 0 and encoded_word != tar_vocab['<sos>'] and encoded_word != tar_vocab['<eos>']):\n",
    "      sentence = sentence + index_to_tar[encoded_word] + ' '\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ddf68ca7-48e6-43e0-90c7-69d6a2ec04e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[125 130  24   0   0   0   0]\n",
      "[   3   21    6 3336   11    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "[  21    6 3336   11    4    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_test[25])\n",
    "print(decoder_input_test[25])\n",
    "print(decoder_target_test[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "57af5dbd-ceeb-4f25-b62c-faedeaceeea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq, model, src_vocab_size, tar_vocab_size, max_output_len, int_to_src_token, int_to_tar_token):\n",
    "    encoder_inputs = torch.tensor(input_seq, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    # 인코더의 초기 상태 설정\n",
    "    hidden, cell = model.encoder(encoder_inputs)\n",
    "\n",
    "    # 시작 토큰 <sos>을 디코더의 첫 입력으로 설정\n",
    "    # unsqueeze(0)는 배치 차원을 추가하기 위함.\n",
    "    decoder_input = torch.tensor([3], dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    decoded_tokens = []\n",
    "\n",
    "    # for문을 도는 것 == 디코더의 각 시점\n",
    "    for _ in range(max_output_len):\n",
    "        output, hidden, cell = model.decoder(decoder_input, hidden, cell)\n",
    "\n",
    "        # 소프트맥스 회귀를 수행. 예측 단어의 인덱스\n",
    "        output_token = output.argmax(dim=-1).item()\n",
    "\n",
    "        # 종료 토큰 <eos>\n",
    "        if output_token == 4:\n",
    "            break\n",
    "\n",
    "        # 각 시점의 단어(정수)는 decoded_tokens에 누적하였다가 최종 번역 시퀀스로 리턴합니다.\n",
    "        decoded_tokens.append(output_token)\n",
    "\n",
    "        # 현재 시점의 예측. 다음 시점의 입력으로 사용된다.\n",
    "        decoder_input = torch.tensor([output_token], dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    return ' '.join(int_to_tar_token[token] for token in decoded_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c472d74c-73d9-4850-8c40-6008cb1f7634",
   "metadata": {},
   "source": [
    "훈련 데이터에 대해서 임의로 선택한 인덱스의 샘플의 결과를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d2b420c-3252-44bb-a006-3f364dc184f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력문장 : i m starved . \n",
      "정답문장 : je meurs de faim ! \n",
      "번역문장 : je suis affame .\n",
      "--------------------------------------------------\n",
      "입력문장 : she didn t go far . \n",
      "정답문장 : elle n est pas allee loin . \n",
      "번역문장 : elle n est pas allee loin .\n",
      "--------------------------------------------------\n",
      "입력문장 : did tom vote ? \n",
      "정답문장 : tom a vote ? \n",
      "번역문장 : tom a vote ?\n",
      "--------------------------------------------------\n",
      "입력문장 : you seem stressed . \n",
      "정답문장 : tu sembles stresse . \n",
      "번역문장 : tu sembles tendu .\n",
      "--------------------------------------------------\n",
      "입력문장 : it was effective . \n",
      "정답문장 : c etait efficace . \n",
      "번역문장 : c etait efficace .\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [3, 50, 100, 300, 1001]:\n",
    "  input_seq = encoder_input_train[seq_index]\n",
    "  translated_text = decode_sequence(input_seq, model, src_vocab_size, tar_vocab_size, 20, index_to_src, index_to_tar)\n",
    "\n",
    "  print(\"입력문장 :\",seq_to_src(encoder_input_train[seq_index]))\n",
    "  print(\"정답문장 :\",seq_to_tar(decoder_input_train[seq_index]))\n",
    "  print(\"번역문장 :\",translated_text)\n",
    "  print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3832c0-5a1e-43a7-8111-7e9ffffb18f6",
   "metadata": {},
   "source": [
    "테스트 데이터에 대해서 임의로 선택한 인덱스의 샘플의 결과를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1c942cf4-3837-44f4-8954-b6b177d6a108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력문장 : tell tom to wait . \n",
      "정답문장 : dis a tom d attendre . \n",
      "번역문장 : dites a tom d attendre .\n",
      "--------------------------------------------------\n",
      "입력문장 : answer me . \n",
      "정답문장 : repondez moi . \n",
      "번역문장 : reponds moi .\n",
      "--------------------------------------------------\n",
      "입력문장 : no problem ! \n",
      "정답문장 : de rien ! \n",
      "번역문장 : pas de probleme !\n",
      "--------------------------------------------------\n",
      "입력문장 : you re powerful . \n",
      "정답문장 : vous etes puissants . \n",
      "번역문장 : vous etes puissante .\n",
      "--------------------------------------------------\n",
      "입력문장 : i ll give it back . \n",
      "정답문장 : je la rendrai . \n",
      "번역문장 : je le rendrai .\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [3, 50, 100, 300, 1001]:\n",
    "  input_seq = encoder_input_test[seq_index]\n",
    "  translated_text = decode_sequence(input_seq, model, src_vocab_size, tar_vocab_size, 20, index_to_src, index_to_tar)\n",
    "\n",
    "  print(\"입력문장 :\",seq_to_src(encoder_input_test[seq_index]))\n",
    "  print(\"정답문장 :\",seq_to_tar(decoder_input_test[seq_index]))\n",
    "  print(\"번역문장 :\",translated_text)\n",
    "  print(\"-\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mecab",
   "language": "python",
   "name": "mecab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
