{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. 시퀀스 레이블링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14-02 양방향 LSTM을 이용한 개체명 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK에서 개체명 인식기 지원\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 인공 신경망을 이용하여 개체명 인식 모델을 만들어봄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. 데이터 로드 및 단어 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/zoohunn/Desktop/비어플/[26-1]스터디/3주차/train.txt',\n",
       " <http.client.HTTPMessage at 0x147bb4e50>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/12.%20RNN%20Sequence%20Labeling/dataset/train.txt\", filename=\"/Users/zoohunn/Desktop/비어플/[26-1]스터디/3주차/train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 후 전체 문장 샘플의 개수 확인\n",
    "f = open('/Users/zoohunn/Desktop/비어플/[26-1]스터디/3주차/train.txt')\n",
    "tagged_sentences = []\n",
    "sentence = []\n",
    "\n",
    "for line in f:\n",
    "    if len(line)==0 or line.startswith('-DOCSTART') or line[0]==\"\\n\":\n",
    "        if len(sentence) > 0:\n",
    "            tagged_sentences.append(sentence)\n",
    "            sentence = []\n",
    "        continue\n",
    "    splits = line.split(' ') # 공백을 기준으로 속성을 구분한다.\n",
    "    splits[-1] = re.sub(r'\\n', '', splits[-1]) # 줄바꿈 표시 \\n을 제거한다.\n",
    "    word = splits[0].lower() # 단어들은 소문자로 바꿔서 저장한다.\n",
    "    sentence.append([word, splits[-1]]) # 단어와 개체명 태깅만 기록한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 개수:  14041\n"
     ]
    }
   ],
   "source": [
    "print(\"전체 샘플 개수: \", len(tagged_sentences)) # 전체 샘플의 개수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['eu', 'B-ORG'], ['rejects', 'O'], ['german', 'B-MISC'], ['call', 'O'], ['to', 'O'], ['boycott', 'O'], ['british', 'B-MISC'], ['lamb', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(tagged_sentences[0]) # 첫 번째 샘플 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 문장 샘플에 대해, 단어는 sentences에, 태깅 정보는 pos_tags에 저장\n",
    "sentences, ner_tags = [], []\n",
    "for tagged_sentence in tagged_sentences: # 14,041개의 문장 샘플을 1개씩 불러옴\n",
    "    sentence, tag_info = zip(*tagged_sentence) # 각 샘플에서 단어들은 sentence에, 개체명 태깅 정보들은 tag_info에 저장\n",
    "    sentences.append(list(sentence)) # 각 샘플에서 단어 정보만 저장\n",
    "    ner_tags.append(list(tag_info)) # 각 샘플에서 개체명 태깅 정보만 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.']\n",
      "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0]) # 첫 번째 샘플의 단어 정보 출력\n",
    "print(ner_tags[0]) # 첫 번째 샘플의 개체명 태깅 정보 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['only', 'france', 'and', 'britain', 'backed', 'fischler', \"'s\", 'proposal', '.']\n",
      "['O', 'B-LOC', 'O', 'B-LOC', 'O', 'B-PER', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[12]) \n",
    "print(ner_tags[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sentences, ner_tags, test_size=0.2, random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 8985\n",
      "검증 데이터의 개수 : 2247\n",
      "테스트 데이터의 개수 : 2809\n",
      "훈련 데이터 레이블의 개수 : 8985\n",
      "검증 데이터 레이블의 개수 : 2247\n",
      "테스트 데이터 레이블의 개수 : 2809\n"
     ]
    }
   ],
   "source": [
    "print('훈련 데이터의 개수 :', len(X_train))\n",
    "print('검증 데이터의 개수 :', len(X_valid))\n",
    "print('테스트 데이터의 개수 :', len(X_test))\n",
    "print('훈련 데이터 레이블의 개수 :', len(X_train))\n",
    "print('검증 데이터 레이블의 개수 :', len(X_valid))\n",
    "print('테스트 데이터 레이블의 개수 :', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['young', 'boys', '9', '1', '0', '8', '6', '19', '3']\n",
      "['hentgen', '(', '17-7', ')', 'surrendered', 'just', 'three', 'doubles', 'and', 'a', 'pair', 'of', 'singles', 'in', 'tossing', 'his', 'major-league', 'leading', 'ninth', 'complete', 'game', '.']\n"
     ]
    }
   ],
   "source": [
    "# 상위 샘플 2개 출력\n",
    "for sent in X_train[:2]:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Vocab 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 단어수 : 16742\n"
     ]
    }
   ],
   "source": [
    "# 각 단어의 빈도수 계산\n",
    "word_list = []\n",
    "for sent in X_train:\n",
    "    for word in sent:\n",
    "        word_list.append(word)\n",
    "\n",
    "word_counts = Counter(word_list)\n",
    "print('총 단어수 :', len(word_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터에서의 단어 the의 등장 횟수 : 5410\n",
      "훈련 데이터에서의 단어 love의 등장 횟수 : 7\n"
     ]
    }
   ],
   "source": [
    "print('훈련 데이터에서의 단어 the의 등장 횟수 :', word_counts['the'])\n",
    "print('훈련 데이터에서의 단어 love의 등장 횟수 :', word_counts['love'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "등장 빈도수 상위 10개 단어\n",
      "['the', ',', '.', 'of', 'in', 'to', 'a', ')', '(', 'and']\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "print('등장 빈도수 상위 10개 단어')\n",
    "print(vocab[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "패딩 토큰과 UNK 토큰을 고려한 단어 집합의 크기 : 16744\n"
     ]
    }
   ],
   "source": [
    "# 단어 집합 만들기 위해 패딩을 위한 토큰, OOV 토큰 추가\n",
    "word_to_index = {}\n",
    "word_to_index['<PAD>'] = 0\n",
    "word_to_index['<UNK>'] = 1\n",
    "\n",
    "for index, word in enumerate(vocab) :\n",
    "  word_to_index[word] = index + 2\n",
    "\n",
    "vocab_size = len(word_to_index)\n",
    "print('패딩 토큰과 UNK 토큰을 고려한 단어 집합의 크기 :', vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def texts_to_sequences(tokenized_X_data, word_to_index):\n",
    "  encoded_X_data = []\n",
    "  for sent in tokenized_X_data:\n",
    "    index_sequences = []\n",
    "    for word in sent:\n",
    "      try:\n",
    "          index_sequences.append(word_to_index[word])\n",
    "      except KeyError:\n",
    "          index_sequences.append(word_to_index['<UNK>'])\n",
    "    encoded_X_data.append(index_sequences)\n",
    "  return encoded_X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_X_train = texts_to_sequences(X_train, word_to_index)\n",
    "encoded_X_valid = texts_to_sequences(X_valid, word_to_index)\n",
    "encoded_X_test = texts_to_sequences(X_test, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1260, 3215, 117, 17, 21, 123, 56, 539, 23]\n",
      "[5456, 10, 8229, 9, 8230, 186, 84, 1815, 11, 8, 1073, 5, 421, 6, 8231, 35, 2043, 291, 790, 957, 267, 4]\n"
     ]
    }
   ],
   "source": [
    "# 상위 샘플 2개 출력\n",
    "for sent in encoded_X_train[:2]:\n",
    "  print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존의 첫번째 샘플 : ['young', 'boys', '9', '1', '0', '8', '6', '19', '3']\n",
      "복원된 첫번째 샘플 : ['young', 'boys', '9', '1', '0', '8', '6', '19', '3']\n"
     ]
    }
   ],
   "source": [
    "index_to_word = {}\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "decoded_sample = [index_to_word[word] for word in encoded_X_train[0]]\n",
    "print('기존의 첫번째 샘플 :', X_train[0])\n",
    "print('복원된 첫번째 샘플 :', decoded_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "태그 집합 : ['O', 'B-LOC', 'B-ORG', 'I-PER', 'I-MISC', 'B-MISC', 'I-ORG', 'I-LOC', 'B-PER']\n",
      "태그 집합의 크기 : 9\n"
     ]
    }
   ],
   "source": [
    "# 레이블에 대한 정수 인코딩도 진행\n",
    "# y_train으로부터 존재하는 모든 태그들의 집합 구하기\n",
    "flatten_tags = [tag for sent in y_train for tag in sent]\n",
    "tag_vocab = list(set(flatten_tags))\n",
    "print('태그 집합 :', tag_vocab)\n",
    "print('태그 집합의 크기 :', len(tag_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "태그 집합 : {'<PAD>': 0, 'O': 1, 'B-LOC': 2, 'B-ORG': 3, 'I-PER': 4, 'I-MISC': 5, 'B-MISC': 6, 'I-ORG': 7, 'I-LOC': 8, 'B-PER': 9}\n"
     ]
    }
   ],
   "source": [
    "tag_to_index = {}\n",
    "tag_to_index['<PAD>'] = 0\n",
    "\n",
    "for index, word in enumerate(tag_vocab) :\n",
    "  tag_to_index[word] = index + 1\n",
    "\n",
    "tag_vocab_size = len(tag_to_index)\n",
    "# print('패딩 토큰까지 포함된 태그 집합의 크기 :', tag_vocab_size)\n",
    "print('태그 집합 :', tag_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다대다 문제의 경우 레이블도 시퀀스 데이터가 되므로 각 레이블을 정수 시퀀스로 변환 해준다 -> 즉, 레이블에 대해서 정수 인코딩을 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_label(sequence, tag_to_index):\n",
    "    label_sequence = []\n",
    "    for seq in sequence:\n",
    "        label_sequence.append([tag_to_index[tag] for tag in seq])\n",
    "    return label_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_y_train = texts_to_sequences(y_train, tag_to_index)\n",
    "encoded_y_valid = texts_to_sequences(y_valid, tag_to_index)\n",
    "encoded_y_test = texts_to_sequences(y_test, tag_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X 데이터 상위 2개\n",
      "[[1260, 3215, 117, 17, 21, 123, 56, 539, 23], [5456, 10, 8229, 9, 8230, 186, 84, 1815, 11, 8, 1073, 5, 421, 6, 8231, 35, 2043, 291, 790, 957, 267, 4]]\n",
      "--------------------------------------------------\n",
      "y 데이터 상위 2개\n",
      "[[3, 7, 1, 1, 1, 1, 1, 1, 1], [9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "--------------------------------------------------\n",
      "첫번째 샘플과 레이블의 길이\n",
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print('X 데이터 상위 2개')\n",
    "print(encoded_X_train[:2])\n",
    "print('-' * 50)\n",
    "print('y 데이터 상위 2개')\n",
    "print(encoded_y_train[:2])\n",
    "print('-' * 50)\n",
    "print('첫번째 샘플과 레이블의 길이')\n",
    "print(len(encoded_X_train[0]))\n",
    "print(len(encoded_y_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 최대 길이 : 78\n",
      "샘플의 평균 길이 : 14.518420\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAGwCAYAAABIC3rIAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAN6pJREFUeJzt3Xt4jHf+//HXJJEQYhAkog7RjaLiUFFF29hF1HG7uqtF0bK7VYoUdVhtHZYE3aKqq0sVW7Xpty3dtloVLfF11qCOX4o4dZNmW5FQmlTy+f3Ry/3rNA4Znclh7ufjuua6zOf+zD3vt3TltZ/75DDGGAEAANiYX0kXAAAAUNIIRAAAwPYIRAAAwPYIRAAAwPYIRAAAwPYIRAAAwPYIRAAAwPYCSrqAsqKgoED/+c9/FBISIofDUdLlAACAIjDG6MKFC4qIiJCf3/XXgQhERfSf//xHderUKekyAADALThz5oxuu+22624nEBVRSEiIpB//QitXrlzC1QAAgKLIyclRnTp1rN/j10MgKqKrh8kqV65MIAIAoIy52ekunFQNAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsj0AEAABsr0QD0aZNm9SzZ09FRETI4XDovffec9lujNGUKVMUERGhChUqqEOHDjp48KDLnNzcXI0YMULVq1dXxYoV1atXL509e9ZlTlZWlgYMGCCn0ymn06kBAwbo/PnzXu4OAACUFSUaiL777js1b95cCxYsuOb22bNna86cOVqwYIF27dql8PBwde7cWRcuXLDmxMfHa/Xq1UpKStLmzZt18eJF9ejRQ/n5+dacfv36ae/evVq7dq3Wrl2rvXv3asCAAV7vDwAAlBGmlJBkVq9ebb0vKCgw4eHhZubMmdbY999/b5xOp3n11VeNMcacP3/elCtXziQlJVlzvvrqK+Pn52fWrl1rjDHm0KFDRpLZvn27NWfbtm1Gkvm///u/IteXnZ1tJJns7OxbbREAABSzov7+LrXnEKWlpSkjI0NxcXHWWFBQkGJjY7V161ZJUmpqqn744QeXOREREWratKk1Z9u2bXI6nWrTpo0155577pHT6bTmXEtubq5ycnJcXgAAwDeV2kCUkZEhSQoLC3MZDwsLs7ZlZGQoMDBQVatWveGcmjVrFtp/zZo1rTnXkpiYaJ1z5HQ6edI9AAA+rNQGoqt+/jA2Y8xNH9D28znXmn+z/UycOFHZ2dnW68yZM25WDgAAyopSG4jCw8MlqdAqTmZmprVqFB4erry8PGVlZd1wztdff11o///9738LrT79VFBQkPVke55wDwCAbyu1gSgyMlLh4eFKTk62xvLy8pSSkqJ27dpJklq1aqVy5cq5zElPT9eBAwesOW3btlV2drZ27txpzdmxY4eys7OtOQAAwN4CSvLLL168qGPHjlnv09LStHfvXlWrVk1169ZVfHy8EhISFBUVpaioKCUkJCg4OFj9+vWTJDmdTg0ZMkRjxoxRaGioqlWrprFjxyo6OlqdOnWSJDVu3FgPPPCA/vSnP+kf//iHJOnPf/6zevTooTvuuKP4my5h9SesuemckzO7F0MlAACUHiUaiD7//HP9+te/tt6PHj1akjRo0CAtW7ZM48aN0+XLlzVs2DBlZWWpTZs2WrdunUJCQqzPzJ07VwEBAerTp48uX76sjh07atmyZfL397fmvPnmmxo5cqR1NVqvXr2ue+8jAABgPw5jjCnpIsqCnJwcOZ1OZWdnl+nziVghAgDYSVF/f5fac4gAAACKC4EIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYHoEIAADYXkBJF4Cyqf6ENTedc3Jm92KoBACAX44VIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHsEIgAAYHtcZVZGcFUXAADewwoRAACwPQIRAACwPQIRAACwPQIRAACwPU6qLgWKcsI0AADwHlaIAACA7RGIAACA7RGIAACA7RGIAACA7RGIAACA7RGIAACA7RGIAACA7RGIAACA7RGIAACA7RGIAACA7RGIAACA7RGIAACA7RGIAACA7RGIAACA7RGIAACA7ZXqQHTlyhU9++yzioyMVIUKFdSgQQNNmzZNBQUF1hxjjKZMmaKIiAhVqFBBHTp00MGDB132k5ubqxEjRqh69eqqWLGievXqpbNnzxZ3OwAAoJQq1YFo1qxZevXVV7VgwQIdPnxYs2fP1gsvvKCXX37ZmjN79mzNmTNHCxYs0K5duxQeHq7OnTvrwoUL1pz4+HitXr1aSUlJ2rx5sy5evKgePXooPz+/JNoCAAClTEBJF3Aj27Zt029/+1t1795dklS/fn3961//0ueffy7px9WhefPmadKkSerdu7ckafny5QoLC9PKlSv1xBNPKDs7W0uWLNEbb7yhTp06SZJWrFihOnXqaP369erSpUvJNAcAAEqNUr1CdO+99+rTTz/V0aNHJUlffPGFNm/erG7dukmS0tLSlJGRobi4OOszQUFBio2N1datWyVJqamp+uGHH1zmREREqGnTptaca8nNzVVOTo7LCwAA+KZSvUI0fvx4ZWdnq1GjRvL391d+fr5mzJihvn37SpIyMjIkSWFhYS6fCwsL06lTp6w5gYGBqlq1aqE5Vz9/LYmJiZo6daon2wEAAKVUqV4heuutt7RixQqtXLlSu3fv1vLly/W3v/1Ny5cvd5nncDhc3htjCo393M3mTJw4UdnZ2dbrzJkzt94IAAAo1Ur1CtEzzzyjCRMm6JFHHpEkRUdH69SpU0pMTNSgQYMUHh4u6cdVoFq1almfy8zMtFaNwsPDlZeXp6ysLJdVoszMTLVr1+663x0UFKSgoCBvtAUAAEqZUr1CdOnSJfn5uZbo7+9vXXYfGRmp8PBwJScnW9vz8vKUkpJihZ1WrVqpXLlyLnPS09N14MCBGwYiAABgH6V6hahnz56aMWOG6tatqzvvvFN79uzRnDlzNHjwYEk/HiqLj49XQkKCoqKiFBUVpYSEBAUHB6tfv36SJKfTqSFDhmjMmDEKDQ1VtWrVNHbsWEVHR1tXnQEAAHsr1YHo5Zdf1nPPPadhw4YpMzNTEREReuKJJ/T8889bc8aNG6fLly9r2LBhysrKUps2bbRu3TqFhIRYc+bOnauAgAD16dNHly9fVseOHbVs2TL5+/uXRFsAAKCUcRhjTEkXURbk5OTI6XQqOztblStX9ui+609Y45H9nJzZ3SPfVZz7AQDAm4r6+7tUn0MEAABQHAhEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9ghEAADA9n5xIMrJydF7772nw4cPe6IeAACAYud2IOrTp48WLFggSbp8+bJiYmLUp08fNWvWTO+++67HCwQAAPA2twPRpk2bdN9990mSVq9eLWOMzp8/r/nz52v69OkeLxAAAMDb3A5E2dnZqlatmiRp7dq1euihhxQcHKzu3bvryy+/9HiBAAAA3uZ2IKpTp462bdum7777TmvXrlVcXJwkKSsrS+XLl/d4gQAAAN4W4O4H4uPj1b9/f1WqVEl169ZVhw4dJP14KC06OtrT9QEAAHid24Fo2LBhuvvuu3XmzBl17txZfn4/LjI1aNCAc4gAAECZ5HYgkqSYmBg1a9ZMaWlpuv322xUQEKDu3bt7ujYAAIBi4fY5RJcuXdKQIUMUHBysO++8U6dPn5YkjRw5UjNnzvR4gQAAAN7mdiCaOHGivvjiC23cuNHlJOpOnTrprbfe8mhxAAAAxcHtQ2bvvfee3nrrLd1zzz1yOBzWeJMmTXT8+HGPFgcAAFAc3F4h+u9//6uaNWsWGv/uu+9cAhIAAEBZ4XYgat26tdasWWO9vxqCFi9erLZt23quMgAAgGLi9iGzxMREPfDAAzp06JCuXLmil156SQcPHtS2bduUkpLijRoBAAC8yu0Vonbt2mnLli26dOmSbr/9dq1bt05hYWHatm2bWrVq5Y0aAQAAvOqW7kMUHR2t5cuXe7oWAACAElGkQJSTk1PkHVauXPmWiwEAACgJRQpEVapUuekVZMYYORwO5efne6QwlJz6E9bcfBIAAD6kSIFow4YN3q4DAACgxBQpEMXGxnq7DgAAgBJzSydVZ2VlacmSJTp8+LAcDocaN26sxx9/XNWqVfN0fQAAAF7n9mX3KSkpql+/vubPn6+srCydO3dO8+fPV2RkJPchAgAAZZLbK0TDhw/Xww8/rIULF8rf31+SlJ+fr2HDhmn48OE6cOCAx4sEAADwJrdXiI4fP64xY8ZYYUiS/P39NXr0aB7uCgAAyiS3A9Fdd92lw4cPFxo/fPiwWrRo4YmaAAAAipXbh8xGjhypUaNG6dixY7rnnnskSdu3b9crr7yimTNnat++fdbcZs2aea5SAAAAL3E7EPXt21eSNG7cuGtuczgc3KQRAACUKW4HorS0NG/UAQAAUGLcDkT16tXzRh0AAAAl5pZuzPjVV19py5YtyszMVEFBgcu2kSNHeqQwAACA4uJ2IFq6dKmGDh2qwMBAhYaGujz01eFwEIgAAECZ43Ygev755/X8889r4sSJ8vNz+6p9AACAUsftRHPp0iU98sgjhCEAAOAz3E41Q4YM0dtvv+2NWq7pq6++0qOPPqrQ0FAFBwerRYsWSk1NtbYbYzRlyhRFRESoQoUK6tChgw4ePOiyj9zcXI0YMULVq1dXxYoV1atXL509e7bYegAAAKWb24fMEhMT1aNHD61du1bR0dEqV66cy/Y5c+Z4rLisrCy1b99ev/71r/Xxxx+rZs2aOn78uKpUqWLNmT17tubMmaNly5apYcOGmj59ujp37qwjR44oJCREkhQfH68PPvhASUlJCg0N1ZgxY9SjRw+lpqa6PIIEAADYk9uBKCEhQZ988onuuOMOSSp0UrUnzZo1S3Xq1NHSpUutsfr161t/NsZo3rx5mjRpknr37i1JWr58ucLCwrRy5Uo98cQTys7O1pIlS/TGG2+oU6dOkqQVK1aoTp06Wr9+vbp06XLN787NzVVubq71Picnx6O9AQCA0sPtQ2Zz5szR66+/rsOHD2vjxo3asGGD9frss888Wtz777+vmJgY/eEPf1DNmjXVsmVLLV682NqelpamjIwMxcXFWWNBQUGKjY3V1q1bJUmpqan64YcfXOZERESoadOm1pxrSUxMlNPptF516tTxaG8AAKD0cDsQBQUFqX379t6opZATJ05o4cKFioqK0ieffKKhQ4dq5MiR+uc//ylJysjIkCSFhYW5fC4sLMzalpGRocDAQFWtWvW6c65l4sSJys7Otl5nzpzxZGsAAKAUcfuQ2ahRo/Tyyy9r/vz53qjHRUFBgWJiYpSQkCBJatmypQ4ePKiFCxdq4MCB1ryfH6q7+iy1G7nZnKCgIAUFBf2C6gEAQFnhdiDauXOnPvvsM3344Ye68847C51UvWrVKo8VV6tWLTVp0sRlrHHjxnr33XclSeHh4ZJ+XAWqVauWNSczM9NaNQoPD1deXp6ysrJcVokyMzPVrl07j9UKAADKLrcPmVWpUkW9e/dWbGysqlev7nKejdPp9Ghx7du315EjR1zGjh49aj1PLTIyUuHh4UpOTra25+XlKSUlxQo7rVq1Urly5VzmpKen68CBAwQiAAAg6RYf3VFcnn76abVr104JCQnq06ePdu7cqUWLFmnRokWSfjxUFh8fr4SEBEVFRSkqKkoJCQkKDg5Wv379JElOp1NDhgzRmDFjFBoaqmrVqmns2LGKjo62rjoDAAD2dksPdy0urVu31urVqzVx4kRNmzZNkZGRmjdvnvr372/NGTdunC5fvqxhw4YpKytLbdq00bp166x7EEnS3LlzFRAQoD59+ujy5cvq2LGjli1bxj2IAACAJMlhjDHufuidd97R//zP/+j06dPKy8tz2bZ7926PFVea5OTkyOl0Kjs7W5UrV/bovutPWOOR/Zyc2b3YvqsoilIPAADeVNTf326fQzR//nw9/vjjqlmzpvbs2aO7775boaGhOnHihLp27fqLigYAACgJbgeiv//971q0aJEWLFigwMBAjRs3TsnJyRo5cqSys7O9USMAAIBXuR2ITp8+bV2dVaFCBV24cEGSNGDAAP3rX//ybHUAAADFwO1AFB4erm+//VaSVK9ePW3fvl3Sj4/RuIXTkQAAAEqc24HoN7/5jT744ANJ0pAhQ/T000+rc+fOevjhh/W73/3O4wUCAAB4m9uX3S9atEgFBQWSpKFDh6patWravHmzevbsqaFDh3q8QAAAAG9zOxD5+fnJz+//Lyz16dNHffr08WhRAAAAxcntQ2Zr167V5s2brfevvPKKWrRooX79+ikrK8ujxQEAABQHtwPRM888o5ycHEnS/v37NXr0aHXr1k0nTpzQ6NGjPV4gAACAt7l9yCwtLc16Av27776rnj17KiEhQbt371a3bt08XiAAAIC3ub1CFBgYqEuXLkmS1q9fr7i4OElStWrVrJUjAACAssTtFaJ7771Xo0ePVvv27bVz50699dZbkqSjR4/qtttu83iBAAAA3ub2CtGCBQsUEBCgd955RwsXLlTt2rUlSR9//LEeeOABjxcIAADgbW6vENWtW1cffvhhofG5c+d6pCAAAIDi5vYKEQAAgK8hEAEAANsjEAEAANsrUiDat2+f9fwyAAAAX1OkQNSyZUt98803kqQGDRro22+/9WpRAAAAxalIgahKlSpKS0uTJJ08eZLVIgAA4FOKdNn9Qw89pNjYWNWqVUsOh0MxMTHy9/e/5twTJ054tEAAAABvK1IgWrRokXr37q1jx45p5MiR+tOf/qSQkBBv1wYAAFAsinxjxqt3oU5NTdWoUaMIRAAAwGe4fafqpUuXWn8+e/asHA6H9fgOAACAssjt+xAVFBRo2rRpcjqdqlevnurWrasqVaror3/9KydbAwCAMsntFaJJkyZpyZIlmjlzptq3by9jjLZs2aIpU6bo+++/14wZM7xRJwAAgNe4HYiWL1+u1157Tb169bLGmjdvrtq1a2vYsGEEIgAAUOa4fcjs3LlzatSoUaHxRo0a6dy5cx4pCgAAoDi5HYiaN2+uBQsWFBpfsGCBmjdv7pGiAAAAipPbh8xmz56t7t27a/369Wrbtq0cDoe2bt2qM2fO6KOPPvJGjQAAAF7l9gpRbGysjh49qt/97nc6f/68zp07p969e+vIkSO67777vFEjAACAV7m9QiRJERERnDwNAAB8htsrRAAAAL7mllaIUDrVn7CmpEsAAKBMYoUIAADYnluByBijU6dO6fLly96qBwAAoNi5HYiioqJ09uxZb9UDAABQ7NwKRH5+foqKitK3337rrXoAAACKndvnEM2ePVvPPPOMDhw44I16AAAAip3bV5k9+uijunTpkpo3b67AwEBVqFDBZTvPMwMAAGWN24Fo3rx5XigDAACg5LgdiAYNGuSNOgAAAErMLd2H6Pjx43r22WfVt29fZWZmSpLWrl2rgwcPerQ4AACA4uB2IEpJSVF0dLR27NihVatW6eLFi5Kkffv2afLkyR4vEAAAwNvcDkQTJkzQ9OnTlZycrMDAQGv817/+tbZt2+bR4gAAAIqD24Fo//79+t3vfldovEaNGtyfCAAAlEluB6IqVaooPT290PiePXtUu3ZtjxQFAABQnNwORP369dP48eOVkZEhh8OhgoICbdmyRWPHjtXAgQO9USMAAIBXuR2IZsyYobp166p27dq6ePGimjRpovvvv1/t2rXTs88+640aAQAAvMrt+xCVK1dOb775pqZNm6Y9e/aooKBALVu2VFRUlDfqAwAA8Dq3A9FVt99+uxo0aCBJcjgcHisIAACguN3SjRmXLFmipk2bqnz58ipfvryaNm2q1157zdO1AQAAFAu3V4iee+45zZ07VyNGjFDbtm0lSdu2bdPTTz+tkydPavr06R4vEgAAwJvcDkQLFy7U4sWL1bdvX2usV69eatasmUaMGEEgAgAAZY7bgSg/P18xMTGFxlu1aqUrV654pCjYR/0Ja2465+TM7sVQCQDAztw+h+jRRx/VwoULC40vWrRI/fv390hRAAAAxalIK0SjR4+2/uxwOPTaa69p3bp1uueeeyRJ27dv15kzZ7gxIwAAKJOKFIj27Nnj8r5Vq1aSpOPHj0v68TlmNWrU0MGDBz1cHgAAgPcVKRBt2LDB23UAAACUmFu6DxEAAIAvcTsQff/993rhhRfUrVs3xcTE6K677nJ5eVNiYqIcDofi4+OtMWOMpkyZooiICFWoUEEdOnQodOguNzdXI0aMUPXq1VWxYkX16tVLZ8+e9WqtAACg7HD7svvBgwcrOTlZv//973X33XcX22M7du3apUWLFqlZs2Yu47Nnz9acOXO0bNkyNWzYUNOnT1fnzp115MgRhYSESJLi4+P1wQcfKCkpSaGhoRozZox69Oih1NRU+fv7F0v9AACg9HI7EK1Zs0YfffSR2rdv7416runixYvq37+/Fi9e7HLjR2OM5s2bp0mTJql3796SpOXLlyssLEwrV67UE088oezsbC1ZskRvvPGGOnXqJElasWKF6tSpo/Xr16tLly7X/M7c3Fzl5uZa73NycrzYIQAAKEluHzKrXbu2tfJSXIYPH67u3btbgeaqtLQ0ZWRkKC4uzhoLCgpSbGystm7dKklKTU3VDz/84DInIiJCTZs2teZcS2JiopxOp/WqU6eOh7sCAAClhduB6MUXX9T48eN16tQpb9RTSFJSknbv3q3ExMRC2zIyMiRJYWFhLuNhYWHWtoyMDAUGBqpq1arXnXMtEydOVHZ2tvU6c+bML20FAACUUm4fMouJidH333+vBg0aKDg4WOXKlXPZfu7cOY8Vd+bMGY0aNUrr1q1T+fLlrzvv5+cxGWNuem7TzeYEBQUpKCjIvYIBAECZ5HYg6tu3r7766islJCQoLCzMqydVp6amKjMz07oRpPTjs9Q2bdqkBQsW6MiRI5J+XAWqVauWNSczM9NaNQoPD1deXp6ysrJcVokyMzPVrl07r9UOAADKDrcD0datW7Vt2zY1b97cG/W46Nixo/bv3+8y9vjjj6tRo0YaP368GjRooPDwcCUnJ6tly5aSpLy8PKWkpGjWrFmSfryrdrly5ZScnKw+ffpIktLT03XgwAHNnj3b6z0AAIDSz+1A1KhRI12+fNkbtRQSEhKipk2buoxVrFhRoaGh1nh8fLwSEhIUFRWlqKgoJSQkKDg4WP369ZMkOZ1ODRkyRGPGjFFoaKiqVaumsWPHKjo6utBJ2gAAwJ7cDkQzZ87UmDFjNGPGDEVHRxc6h6hy5coeK64oxo0bp8uXL2vYsGHKyspSmzZttG7dOpcr4ebOnauAgAD16dNHly9fVseOHbVs2TLuQQQAACRJDmOMcecDfn4/Xph2vROZ8/PzPVddKZKTkyOn06ns7GyPh776E9Z4dH+lxcmZ3W86pyi9F2U/AABcS1F/f7u9QsSDXgEAgK9xOxDFxsZ6ow4AAIAS43Yg2rRp0w2333///bdcDAAAQElwOxB16NCh0NhPzyfy1XOIAACA73L70R1ZWVkur8zMTK1du1atW7fWunXrvFEjAACAV7m9QuR0OguNde7cWUFBQXr66aeVmprqkcIAAACKi9srRNdTo0YN61EaAAAAZYnbK0T79u1zeW+MUXp6umbOnFksj/MAAADwNLcDUYsWLeRwOPTz+znec889ev311z1WGAAAQHFxOxClpaW5vPfz81ONGjVUvnx5jxUFAABQnNwORPXq1fNGHQAAACXG7UAkSZ9++qk+/fRTZWZmqqCgwGUbh80AAEBZ43Ygmjp1qqZNm6aYmBjVqlWr0ENeAQAAyhq3A9Grr76qZcuWacCAAd6oBwAAoNi5fR+ivLw8tWvXzhu1AAAAlAi3A9Ef//hHrVy50hu1AAAAlAi3D5l9//33WrRokdavX69mzZqpXLlyLtvnzJnjseIAAACKwy3dqbpFixaSpAMHDrhs4wRrAABQFrkdiDZs2OCNOgAAAEqMxx7uCgAAUFbd0o0ZgdKm/oQ1RZp3cmZ3L1cCACiLWCECAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2F1DSBQBlUf0Ja2465+TM7sVQCQDAE1ghAgAAtscKEVCCWGkCgNKBFSIAAGB7BCIAAGB7BCIAAGB7BCIAAGB7nFQN/ExRTnT2VZzkDcCuWCECAAC2RyACAAC2xyEzwAdwqAsAfhkCEbzGzufiAADKFg6ZAQAA2yMQAQAA2yMQAQAA2yMQAQAA2yMQAQAA2+MqMwAex20AAJQ1rBABAADbIxABAADbIxABAADbIxABAADbIxABAADbIxABAADbK9WBKDExUa1bt1ZISIhq1qypBx98UEeOHHGZY4zRlClTFBERoQoVKqhDhw46ePCgy5zc3FyNGDFC1atXV8WKFdWrVy+dPXu2OFsBAAClWKkORCkpKRo+fLi2b9+u5ORkXblyRXFxcfruu++sObNnz9acOXO0YMEC7dq1S+Hh4ercubMuXLhgzYmPj9fq1auVlJSkzZs36+LFi+rRo4fy8/NLoi0AAFDKlOobM65du9bl/dKlS1WzZk2lpqbq/vvvlzFG8+bN06RJk9S7d29J0vLlyxUWFqaVK1fqiSeeUHZ2tpYsWaI33nhDnTp1kiStWLFCderU0fr169WlS5di7wsAAJQupXqF6Oeys7MlSdWqVZMkpaWlKSMjQ3FxcdacoKAgxcbGauvWrZKk1NRU/fDDDy5zIiIi1LRpU2vOteTm5ionJ8flBQAAfFOZCUTGGI0ePVr33nuvmjZtKknKyMiQJIWFhbnMDQsLs7ZlZGQoMDBQVatWve6ca0lMTJTT6bRederU8WQ7AACgFCnVh8x+6qmnntK+ffu0efPmQtscDofLe2NMobGfu9mciRMnavTo0db7nJwcQlEJKcpzsQAA+CXKxArRiBEj9P7772vDhg267bbbrPHw8HBJKrTSk5mZaa0ahYeHKy8vT1lZWdedcy1BQUGqXLmyywsAAPimUh2IjDF66qmntGrVKn322WeKjIx02R4ZGanw8HAlJydbY3l5eUpJSVG7du0kSa1atVK5cuVc5qSnp+vAgQPWHAAAYG+l+pDZ8OHDtXLlSv373/9WSEiItRLkdDpVoUIFORwOxcfHKyEhQVFRUYqKilJCQoKCg4PVr18/a+6QIUM0ZswYhYaGqlq1aho7dqyio6Otq84AAIC9lepAtHDhQklShw4dXMaXLl2qxx57TJI0btw4Xb58WcOGDVNWVpbatGmjdevWKSQkxJo/d+5cBQQEqE+fPrp8+bI6duyoZcuWyd/fv7haAQAApVipDkTGmJvOcTgcmjJliqZMmXLdOeXLl9fLL7+sl19+2YPVAQAAX1GqzyECAAAoDqV6hQiAvRXllgsnZ3YvhkoA+DpWiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO0RiAAAgO1xp2qglCvK3ZoBAL8MgQjwEl8NMr7aFwB7IxDBVvhlDgC4Fs4hAgAAtscKEWATdl4dK0rvJ2d2L4ZKAJRWrBABAADbIxABAADbIxABAADbIxABAADbIxABAADbIxABAADbIxABAADbIxABAADbIxABAADbIxABAADb49EdACAe7wHYHStEAADA9ghEAADA9ghEAADA9ghEAADA9jipGkCJKMpJzABQXFghAgAAtkcgAgAAtkcgAgAAtkcgAgAAtkcgAgAAtsdVZgDKNK5WA+AJrBABAADbIxABAADbIxABAADbIxABAADb46RqAPCgopzkfXJm92KoBIA7WCECAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2RyACAAC2x40ZAaCIinLTRQBlE4EIAEoh7ngNFC8CEQAUM1aagNKHc4gAAIDtEYgAAIDtEYgAAIDtEYgAAIDtEYgAAIDtcZUZAPgwT12+z20A4OtsFYj+/ve/64UXXlB6erruvPNOzZs3T/fdd19JlwUAt4TL9wHPsc0hs7feekvx8fGaNGmS9uzZo/vuu09du3bV6dOnS7o0AABQwhzGGFPSRRSHNm3a6K677tLChQutscaNG+vBBx9UYmLiTT+fk5Mjp9Op7OxsVa5c2aO18f/yAPgCDpmhNCrq729bHDLLy8tTamqqJkyY4DIeFxenrVu3XvMzubm5ys3Ntd5nZ2dL+vEv1tMKci95fJ8AUNzqPv12SZfgFQemdvHIfppO/qTYvqu0Kcner/7evtn6jy0C0TfffKP8/HyFhYW5jIeFhSkjI+Oan0lMTNTUqVMLjdepU8crNQIASifnPN/8rtLG271fuHBBTqfzutttEYiucjgcLu+NMYXGrpo4caJGjx5tvS8oKNC5c+cUGhp63c/cSE5OjurUqaMzZ854/JBbaUOvvscufUr26dUufUr26dUufUru9WqM0YULFxQREXHDebYIRNWrV5e/v3+h1aDMzMxCq0ZXBQUFKSgoyGWsSpUqv7iWypUr+/x/qFfRq++xS5+SfXq1S5+SfXq1S59S0Xu90crQVba4yiwwMFCtWrVScnKyy3hycrLatWtXQlUBAIDSwhYrRJI0evRoDRgwQDExMWrbtq0WLVqk06dPa+jQoSVdGgAAKGG2CUQPP/ywvv32W02bNk3p6elq2rSpPvroI9WrV69Yvj8oKEiTJ08udBjOF9Gr77FLn5J9erVLn5J9erVLn5J3erXNfYgAAACuxxbnEAEAANwIgQgAANgegQgAANgegQgAANgegaiY/P3vf1dkZKTKly+vVq1a6X//939LuqRfbNOmTerZs6ciIiLkcDj03nvvuWw3xmjKlCmKiIhQhQoV1KFDBx08eLBkiv0FEhMT1bp1a4WEhKhmzZp68MEHdeTIEZc5vtDrwoUL1axZM+tGZ23bttXHH39sbfeFHq8nMTFRDodD8fHx1pgv9DtlyhQ5HA6XV3h4uLXdF3r8qa+++kqPPvqoQkNDFRwcrBYtWig1NdXa7iv91q9fv9DP1eFwaPjw4ZJ8p88rV67o2WefVWRkpCpUqKAGDRpo2rRpKigosOZ4tFcDr0tKSjLlypUzixcvNocOHTKjRo0yFStWNKdOnSrp0n6Rjz76yEyaNMm8++67RpJZvXq1y/aZM2eakJAQ8+6775r9+/ebhx9+2NSqVcvk5OSUTMG3qEuXLmbp0qXmwIEDZu/evaZ79+6mbt265uLFi9YcX+j1/fffN2vWrDFHjhwxR44cMX/5y19MuXLlzIEDB4wxvtHjtezcudPUr1/fNGvWzIwaNcoa94V+J0+ebO68806Tnp5uvTIzM63tvtDjVefOnTP16tUzjz32mNmxY4dJS0sz69evN8eOHbPm+Eq/mZmZLj/T5ORkI8ls2LDBGOM7fU6fPt2EhoaaDz/80KSlpZm3337bVKpUycybN8+a48leCUTF4O677zZDhw51GWvUqJGZMGFCCVXkeT8PRAUFBSY8PNzMnDnTGvv++++N0+k0r776aglU6DmZmZlGkklJSTHG+HavVatWNa+99prP9njhwgUTFRVlkpOTTWxsrBWIfKXfyZMnm+bNm19zm6/0eNX48ePNvffee93tvtbvT40aNcrcfvvtpqCgwKf67N69uxk8eLDLWO/evc2jjz5qjPH8z5RDZl6Wl5en1NRUxcXFuYzHxcVp69atJVSV96WlpSkjI8Ol76CgIMXGxpb5vrOzsyVJ1apVk+Sbvebn5yspKUnfffed2rZt65M9StLw4cPVvXt3derUyWXcl/r98ssvFRERocjISD3yyCM6ceKEJN/qUZLef/99xcTE6A9/+INq1qypli1bavHixdZ2X+v3qry8PK1YsUKDBw+Ww+HwqT7vvfdeffrppzp69Kgk6YsvvtDmzZvVrVs3SZ7/mdrmTtUl5ZtvvlF+fn6hh8iGhYUVetisL7na27X6PnXqVEmU5BHGGI0ePVr33nuvmjZtKsm3et2/f7/atm2r77//XpUqVdLq1avVpEkT6x8XX+jxqqSkJO3evVu7du0qtM1XfqZt2rTRP//5TzVs2FBff/21pk+frnbt2ungwYM+0+NVJ06c0MKFCzV69Gj95S9/0c6dOzVy5EgFBQVp4MCBPtfvVe+9957Onz+vxx57TJLv/LcrSePHj1d2drYaNWokf39/5efna8aMGerbt68kz/dKIComDofD5b0xptCYL/K1vp966int27dPmzdvLrTNF3q94447tHfvXp0/f17vvvuuBg0apJSUFGu7L/QoSWfOnNGoUaO0bt06lS9f/rrzynq/Xbt2tf4cHR2ttm3b6vbbb9fy5ct1zz33SCr7PV5VUFCgmJgYJSQkSJJatmypgwcPauHChRo4cKA1z1f6vWrJkiXq2rWrIiIiXMZ9oc+33npLK1as0MqVK3XnnXdq7969io+PV0REhAYNGmTN81SvHDLzsurVq8vf37/QalBmZmahVOtLrl7J4kt9jxgxQu+//742bNig2267zRr3pV4DAwP1q1/9SjExMUpMTFTz5s310ksv+VSPkpSamqrMzEy1atVKAQEBCggIUEpKiubPn6+AgACrJ1/p96qKFSsqOjpaX375pc/9TGvVqqUmTZq4jDVu3FinT5+W5Fv/O73q1KlTWr9+vf74xz9aY77U5zPPPKMJEybokUceUXR0tAYMGKCnn35aiYmJkjzfK4HIywIDA9WqVSslJye7jCcnJ6tdu3YlVJX3RUZGKjw83KXvvLw8paSklLm+jTF66qmntGrVKn322WeKjIx02e5Lvf6cMUa5ubk+12PHjh21f/9+7d2713rFxMSof//+2rt3rxo0aOBT/V6Vm5urw4cPq1atWj73M23fvn2h22EcPXrUeoC3r/UrSUuXLlXNmjXVvXt3a8yX+rx06ZL8/Fxjir+/v3XZvcd7df+8b7jr6mX3S5YsMYcOHTLx8fGmYsWK5uTJkyVd2i9y4cIFs2fPHrNnzx4jycyZM8fs2bPHup3AzJkzjdPpNKtWrTL79+83ffv2LZOXfj755JPG6XSajRs3ulzqeunSJWuOL/Q6ceJEs2nTJpOWlmb27dtn/vKXvxg/Pz+zbt06Y4xv9HgjP73KzBjf6HfMmDFm48aN5sSJE2b79u2mR48eJiQkxPq3xxd6vGrnzp0mICDAzJgxw3z55ZfmzTffNMHBwWbFihXWHF/qNz8/39StW9eMHz++0DZf6XPQoEGmdu3a1mX3q1atMtWrVzfjxo2z5niyVwJRMXnllVdMvXr1TGBgoLnrrrusS7bLsg0bNhhJhV6DBg0yxvx4SeTkyZNNeHi4CQoKMvfff7/Zv39/yRZ9C67VoySzdOlSa44v9Dp48GDrv9EaNWqYjh07WmHIGN/o8UZ+Hoh8od+r92QpV66ciYiIML179zYHDx60tvtCjz/1wQcfmKZNm5qgoCDTqFEjs2jRIpftvtTvJ598YiSZI0eOFNrmK33m5OSYUaNGmbp165ry5cubBg0amEmTJpnc3Fxrjid7dRhjjPvrSgAAAL6Dc4gAAIDtEYgAAIDtEYgAAIDtEYgAAIDtEYgAAIDtEYgAAIDtEYgAAIDtEYgAAIDtEYgAFNKhQwfFx8eXdBmSpI0bN8rhcOj8+fMe3/eUKVMUFhYmh8Oh9957z+P795aTJ0/K4XBo7969JV0K4DMIRABKjeIMYocPH9bUqVP1j3/8Q+np6eratWuxfC+A0imgpAsAgJJw/PhxSdJvf/tbORyOEq4GQEljhQjATeXl5WncuHGqXbu2KlasqDZt2mjjxo3W9mXLlqlKlSr65JNP1LhxY1WqVEkPPPCA0tPTrTlXrlzRyJEjVaVKFYWGhmr8+PEaNGiQHnzwQUnSY489ppSUFL300ktyOBxyOBw6efKk9fnU1FTFxMQoODhY7dq105EjR25Y8/79+/Wb3/xGFSpUUGhoqP785z/r4sWLkn48VNazZ09Jkp+f33UDUVZWlvr3768aNWqoQoUKioqK0tKlS63t48ePV8OGDRUcHKwGDRroueee0w8//GBtnzJlilq0aKHXX39ddevWVaVKlfTkk08qPz9fs2fPVnh4uGrWrKkZM2a4fK/D4dDChQvVtWtXVahQQZGRkXr77bdv2O+hQ4fUrVs3VapUSWFhYRowYIC++eYba/s777yj6Oho6++jU6dO+u677264T8BOCEQAburxxx/Xli1blJSUpH379ukPf/iDHnjgAX355ZfWnEuXLulvf/ub3njjDW3atEmnT5/W2LFjre2zZs3Sm2++qaVLl2rLli3KyclxOW/npZdeUtu2bfWnP/1J6enpSk9PV506daztkyZN0osvvqjPP/9cAQEBGjx48HXrvXTpkh544AFVrVpVu3bt0ttvv63169frqaeekiSNHTvWCjZXv+tannvuOR06dEgff/yxDh8+rIULF6p69erW9pCQEC1btkyHDh3SSy+9pMWLF2vu3Lku+zh+/Lg+/vhjrV27Vv/617/0+uuvq3v37jp79qxSUlI0a9YsPfvss9q+fXuh737ooYf0xRdf6NFHH1Xfvn11+PDha9aZnp6u2NhYtWjRQp9//rnWrl2rr7/+Wn369LG29+3bV4MHD9bhw4e1ceNG9e7dWzzbG/gJAwA/Exsba0aNGmWMMebYsWPG4XCYr776ymVOx44dzcSJE40xxixdutRIMseOHbO2v/LKKyYsLMx6HxYWZl544QXr/ZUrV0zdunXNb3/722t+71UbNmwwksz69eutsTVr1hhJ5vLly9esf9GiRaZq1arm4sWLLp/x8/MzGRkZxhhjVq9ebW72T2DPnj3N448/fsM5PzV79mzTqlUr6/3kyZNNcHCwycnJsca6dOli6tevb/Lz862xO+64wyQmJlrvJZmhQ4e67LtNmzbmySefNMYYk5aWZiSZPXv2GGOMee6550xcXJzL/DNnzhhJ5siRIyY1NdVIMidPnixyL4DdcA4RgBvavXu3jDFq2LChy3hubq5CQ0Ot98HBwbr99tut97Vq1VJmZqYkKTs7W19//bXuvvtua7u/v79atWqlgoKCItXRrFkzl31LUmZmpurWrVto7uHDh9W8eXNVrFjRGmvfvr0KCgp05MgRhYWFFek7n3zyST300EPavXu34uLi9OCDD6pdu3bW9nfeeUfz5s3TsWPHdPHiRV25ckWVK1d22Uf9+vUVEhJivQ8LC5O/v7/8/Pxcxq7+XV3Vtm3bQu+vd1VZamqqNmzYoEqVKhXadvz4ccXFxaljx46Kjo5Wly5dFBcXp9///veqWrVqkf4eADsgEAG4oYKCAvn7+ys1NVX+/v4u2376C7hcuXIu2xwOR6FDMj8/V+fn22/kp/u/up/rhSljzHXPC3LnBOquXbvq1KlTWrNmjdavX6+OHTtq+PDh+tvf/qbt27frkUce0dSpU9WlSxc5nU4lJSXpxRdfvG7dV7//WmNFCYbXq72goEA9e/bUrFmzCm2rVauW/P39lZycrK1bt2rdunV6+eWXNWnSJO3YsUORkZE3/V7ADjiHCMANtWzZUvn5+crMzNSvfvUrl1d4eHiR9uF0OhUWFqadO3daY/n5+dqzZ4/LvMDAQOXn5//imps0aaK9e/e6nDS8ZcsW+fn5FVrpupkaNWroscce04oVKzRv3jwtWrTI2l+9evU0adIkxcTEKCoqSqdOnfrFtV/183OKtm/frkaNGl1z7l133aWDBw+qfv36hX5GV1fJHA6H2rdvr6lTp2rPnj0KDAzU6tWrPVYvUNYRiADcUMOGDdW/f38NHDhQq1atUlpamnbt2qVZs2bpo48+KvJ+RowYocTERP373//WkSNHNGrUKGVlZbmsetSvX187duzQyZMn9c033xT5cNrP9e/fX+XLl9egQYN04MABbdiwQSNGjNCAAQOKfLhMkp5//nn9+9//1rFjx3Tw4EF9+OGHaty4sSTpV7/6lU6fPq2kpCQdP35c8+fP92jAePvtt/X666/r6NGjmjx5snbu3GmdFP5zw4cP17lz59S3b1/t3LlTJ06c0Lp16zR48GDl5+drx44dSkhI0Oeff67Tp09r1apV+u9//2v1AoBABKAIli5dqoEDB2rMmDG644471KtXL+3YscPlKrCbGT9+vPr27auBAweqbdu2qlSpkrp06aLy5ctbc8aOHSt/f381adJENWrU0OnTp2+p3uDgYH3yySc6d+6cWrdurd///vfq2LGjFixY4NZ+AgMDNXHiRDVr1kz333+//P39lZSUJOnH+xc9/fTTeuqpp9SiRQtt3bpVzz333C3Vey1Tp05VUlKSmjVrpuXLl+vNN99UkyZNrjk3IiJCW7ZsUX5+vrp06aKmTZtq1KhRcjqd8vPzU+XKlbVp0yZ169ZNDRs21LPPPqsXX3yRm1ECP+Ew7hzEBwAPKSgoUOPGjdWnTx/99a9/LelyShWHw6HVq1db92gC4H2cVA2gWJw6dUrr1q1TbGyscnNztWDBAqWlpalfv34lXRoAcMgMQPHw8/PTsmXL1Lp1a7Vv31779+/X+vXrOY8FQKnAITMAAGB7rBABAADbIxABAADbIxABAADbIxABAADbIxABAADbIxABAADbIxABAADbIxABAADb+3+Gpv0hJMRWMQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('샘플의 최대 길이 : %d' % max(len(l) for l in encoded_X_train))\n",
    "print('샘플의 평균 길이 : %f' % (sum(map(len, encoded_X_train))/len(encoded_X_train)))\n",
    "plt.hist([len(s) for s in encoded_X_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_len 설정\n",
    "def below_threshold_len(max_len, nested_list):\n",
    "  count = 0\n",
    "  for sentence in nested_list:\n",
    "    if(len(sentence) <= max_len):\n",
    "        count = count + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (count / len(nested_list))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 80 이하인 샘플의 비율: 100.0\n"
     ]
    }
   ],
   "source": [
    "max_len = 80\n",
    "below_threshold_len(max_len, encoded_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_len 보다 짧은 데이터의 경우에는 뒤에 0을 추가하는 함수\n",
    "def pad_sequences(sentences, max_len):\n",
    "    features = np.zeros((len(sentences), max_len), dtype=int)\n",
    "    for index, sentence in enumerate(sentences):\n",
    "        if len(sentence) != 0:\n",
    "            features[index, :len(sentence)] = np.array(sentence)[:max_len]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "개체명 인식과 같은 many-to-many 문제를 푸는 경우 레이블도 패딩해줘야하는 것 기억"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 크기 : (8985, 80)\n",
      "검증 데이터의 크기 : (2247, 80)\n",
      "테스트 데이터의 크기 : (2809, 80)\n",
      "------------------------------\n",
      "훈련 데이터의 레이블 : (8985, 80)\n",
      "검증 데이터의 레이블 : (2247, 80)\n",
      "테스트 데이터의 레이블 : (2809, 80)\n"
     ]
    }
   ],
   "source": [
    "padded_X_train = pad_sequences(encoded_X_train, max_len=max_len)\n",
    "padded_X_valid = pad_sequences(encoded_X_valid, max_len=max_len)\n",
    "padded_X_test = pad_sequences(encoded_X_test, max_len=max_len)\n",
    "\n",
    "padded_y_train = pad_sequences(encoded_y_train, max_len=max_len)\n",
    "padded_y_valid = pad_sequences(encoded_y_valid, max_len=max_len)\n",
    "padded_y_test = pad_sequences(encoded_y_test, max_len=max_len)\n",
    "\n",
    "print('훈련 데이터의 크기 :', padded_X_train.shape)\n",
    "print('검증 데이터의 크기 :', padded_X_valid.shape)\n",
    "print('테스트 데이터의 크기 :', padded_X_test.shape)\n",
    "print('-' * 30)\n",
    "print('훈련 데이터의 레이블 :', padded_y_train.shape)\n",
    "print('검증 데이터의 레이블 :', padded_y_valid.shape)\n",
    "print('테스트 데이터의 레이블 :', padded_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 상위 샘플 2개\n",
      "[[1260 3215  117   17   21  123   56  539   23    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0]\n",
      " [5456   10 8229    9 8230  186   84 1815   11    8 1073    5  421    6\n",
      "  8231   35 2043  291  790  957  267    4    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0]]\n",
      "-----레이블-----\n",
      "[[3 7 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0]\n",
      " [9 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print('훈련 데이터의 상위 샘플 2개')\n",
    "print(padded_X_train[:2])\n",
    "print('-' * 5 + '레이블' + '-' * 5)\n",
    "print(padded_y_train[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu와 cuda 중 다음 기기로 학습함: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"cpu와 cuda 중 다음 기기로 학습함:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n단방향 GRU 모델인 경우,\\n\\nclass NERTagger(nn.Module):\\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\\n        super(NERTagger, self).__init__()\\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\\n        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\\n        self.fc = nn.Linear(hidden_dim, output_dim)\\n\\n    def forward(self, x):\\n        # x: (batch_size, seq_length)\\n        embedded = self.embedding(x)  # (batch_size, seq_length, embedding_dim)\\n        gru_out, _ = self.gru(embedded)  # (batch_size, seq_length, hidden_dim)\\n        logits = self.fc(gru_out)  # (batch_size, seq_length, output_dim)\\n        return logits\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "단방향 GRU 모델인 경우,\n",
    "\n",
    "class NERTagger(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(NERTagger, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_length)\n",
    "        embedded = self.embedding(x)  # (batch_size, seq_length, embedding_dim)\n",
    "        gru_out, _ = self.gru(embedded)  # (batch_size, seq_length, hidden_dim)\n",
    "        logits = self.fc(gru_out)  # (batch_size, seq_length, output_dim)\n",
    "        return logits\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 양방향 LSTM 2층 모델\n",
    "\n",
    "class NERTagger(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, num_layers=2):\n",
    "        super(NERTagger, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=True) # bidirectional=True -> 양방향 LSTM\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_dim) # hidden_dim*2 -> 양방향 LSTM이므로 hidden_dim에 2를 곱함\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_length)\n",
    "        embedded = self.embedding(x)  # (batch_size, seq_length, embedding_dim)\n",
    "        lstm_out, _ = self.lstm(embedded)  # (batch_size, seq_length, hidden_dim*2)\n",
    "        logits = self.fc(lstm_out)  # (batch_size, seq_length, output_dim)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(padded_X_train, dtype=torch.long)\n",
    "y_train_tensor = torch.tensor(padded_y_train, dtype=torch.long)\n",
    "X_valid_tensor = torch.tensor(padded_X_valid, dtype=torch.long)\n",
    "y_valid_tensor = torch.tensor(padded_y_valid, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(padded_X_test, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(padded_y_test, dtype=torch.long)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=32)\n",
    "valid_dataset = torch.utils.data.TensorDataset(X_valid_tensor, y_valid_tensor)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, shuffle=False, batch_size=32)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, shuffle=False, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기: 16744\n"
     ]
    }
   ],
   "source": [
    "print('단어 집합의 크기:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "output_dim = tag_vocab_size\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10\n",
    "num_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 객체 및 손실함수 및 최적화 함수 정의\n",
    "model = NERTagger(vocab_size, embedding_dim, hidden_dim, output_dim, num_layers)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0) # ignore_index=0을 통해 패딩 토큰에 대한 손실은 계산하지 않음\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. 평가 코드 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 평가 함수 정의\n",
    "def calculate_accuracy(logits, labels, ignore_index=0):\n",
    "    predicted = torch.argmax(logits, dim=1)                          # 예측 레이블을 구함\n",
    "    mask = (labels != ignore_index)                                  # 패딩 토큰은 무시해서 계산하지 않도록 함\n",
    "    correct = (predicted == labels).masked_select(mask).sum().item() # 정답을 맞춘 경우를 집계\n",
    "    total = mask.sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 데이터에 대한 정확도와 loss 계산 함수 정의\n",
    "def evaluate(model, valid_dataloader, criterion, device):\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in valid_dataloader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            logits = model(batch_X)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(logits.view(-1, output_dim), batch_y.view(-1))\n",
    "\n",
    "            # Calculate validation accuracy and loss\n",
    "            val_loss += loss.item()\n",
    "            val_correct += calculate_accuracy(logits.view(-1, output_dim), batch_y.view(-1)) * batch_y.size(0)\n",
    "            val_total += batch_y.size(0)\n",
    "\n",
    "    val_accuracy = val_correct / val_total\n",
    "    val_loss /= len(valid_dataloader)\n",
    "\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:\n",
      "Train Loss: 0.0849, Train Accuracy: 0.9756\n",
      "Validation Loss: 0.2022, Validation Accuracy: 0.9519\n",
      "Validation loss improved from inf to 0.2022. 체크포인트를 저장합니다.\n",
      "Epoch 2/5:\n",
      "Train Loss: 0.0403, Train Accuracy: 0.9881\n",
      "Validation Loss: 0.2742, Validation Accuracy: 0.9513\n",
      "Epoch 3/5:\n",
      "Train Loss: 0.0263, Train Accuracy: 0.9917\n",
      "Validation Loss: 0.2920, Validation Accuracy: 0.9513\n",
      "Epoch 4/5:\n",
      "Train Loss: 0.0230, Train Accuracy: 0.9928\n",
      "Validation Loss: 0.2758, Validation Accuracy: 0.9526\n",
      "Epoch 5/5:\n",
      "Train Loss: 0.0221, Train Accuracy: 0.9931\n",
      "Validation Loss: 0.2880, Validation Accuracy: 0.9529\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "# Training loop\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    model.train()\n",
    "    for batch_X, batch_y in train_dataloader:\n",
    "        # Forward pass\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        logits = model(batch_X)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(logits.view(-1, output_dim), batch_y.view(-1))\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate training accuracy and loss\n",
    "        train_loss += loss.item()\n",
    "        train_correct += calculate_accuracy(logits.view(-1, output_dim), batch_y.view(-1)) * batch_y.size(0)\n",
    "        train_total += batch_y.size(0)\n",
    "\n",
    "    train_accuracy = train_correct / train_total\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    # Validation\n",
    "    val_loss, val_accuracy = evaluate(model, valid_dataloader, criterion, device)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # 검증 손실이 최소일 때 체크포인트 저장\n",
    "    if val_loss < best_val_loss:\n",
    "        print(f'Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. 체크포인트를 저장합니다.')\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), '/Users/zoohunn/Desktop/비어플/[26-1]스터디/3주차/best_model_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. 모델 로드 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model validation loss: 0.2022\n",
      "Best model validation accuracy: 0.9519\n"
     ]
    }
   ],
   "source": [
    "# 모델 로드\n",
    "model.load_state_dict(torch.load('/Users/zoohunn/Desktop/비어플/[26-1]스터디/3주차/best_model_checkpoint.pth'))\n",
    "\n",
    "# 모델을 device에 올립니다.\n",
    "model.to(device)\n",
    "\n",
    "# 검증 데이터에 대한 정확도(accuracy)와 손실(loss) 계산\n",
    "val_loss, val_accuracy = evaluate(model, valid_dataloader, criterion, device)\n",
    "\n",
    "print(f'Best model validation loss: {val_loss:.4f}')\n",
    "print(f'Best model validation accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9.인피런스(테스트)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_tag = {}\n",
    "for key, value in tag_to_index.items():\n",
    "    index_to_tag[value] = key\n",
    "\n",
    "def predict_labels(text, model, word_to_ix, index_to_tag, max_len=150):\n",
    "    # 단어 토큰화\n",
    "    tokens = text.split()\n",
    "\n",
    "    # 정수 인코딩\n",
    "    token_indices = [word_to_ix.get(token, 1) for token in tokens]\n",
    "\n",
    "    # 패딩\n",
    "    token_indices_padded = np.zeros(max_len, dtype=int)\n",
    "    token_indices_padded[:len(token_indices)] = token_indices[:max_len]\n",
    "\n",
    "    # 텐서로 변환\n",
    "    input_tensor = torch.tensor(token_indices_padded, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    # 모델의 입력으로 사용하고 예측값 리턴\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)\n",
    "\n",
    "    # 가장 값이 높은 인덱스를 예측값으로 선택\n",
    "    predicted_indices = torch.argmax(logits, dim=-1).squeeze(0).tolist()\n",
    "\n",
    "    # 패딩 토큰 제거\n",
    "    predicted_indices_no_pad = predicted_indices[:len(tokens)]\n",
    "\n",
    "    # 패딩 토큰을 제외하고 정수 시퀀스를 예측 시퀀스로 변환\n",
    "    predicted_tags = [index_to_tag[index] for index in predicted_indices_no_pad]\n",
    "\n",
    "    return predicted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feyenoord', 'rotterdam', 'suffered', 'an', 'early', 'shock', 'when', 'they', 'went', '1-0', 'down', 'after', 'four', 'minutes', 'against', 'de', 'graafschap', 'doetinchem', '.']\n"
     ]
    }
   ],
   "source": [
    "print(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feyenoord rotterdam suffered an early shock when they went 1-0 down after four minutes against de graafschap doetinchem .\n"
     ]
    }
   ],
   "source": [
    "sample = ' '.join(X_test[0])\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 : ['B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O']\n",
      "실제값 : ['B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O']\n"
     ]
    }
   ],
   "source": [
    "predicted_tags = predict_labels(sample, model, word_to_index, index_to_tag)\n",
    "print('예측 :', predicted_tags)\n",
    "print('실제값 :', y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위는 잘 예측됨 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
